{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this project, we are given some data gathered about various features of forests. Each data row represents a 30x30\n",
    "# meter area of forest and several relevant features that correspond to that area.\n",
    "\n",
    "# For each data point, 12 characteristics of that area of forest were gathered:\n",
    "# -Elevation in meters\n",
    "# -Aspect: the direction of the slope in degrees azimuth (0-359)\n",
    "# -Slope: in degrees\n",
    "# -Horizontal_Distance_To_Hydrology: in meters\n",
    "# -Vertical_Distance_To_Hydrology: in meters\n",
    "# -Horizontal_Distance_To_Roadways: in meters\n",
    "# -Hillshade_9am: from 0-255\n",
    "# -Hillshade_noon: from 0-255\n",
    "# -Hillshade_3pm: from 0-255\n",
    "# -Horizontal_Distance_To_Fire_Points: in meters\n",
    "# -Wilderness_Area: categorical feature for 4 different wilderness areas (Rawah, Neota, Comanche Peak, Cache la Poudre).\n",
    "#      Luckily, broken out into a 40-feature one-hot encoding for us already.\n",
    "# -Soil_Type: categorical for 40 different soil types. Luckily, broken out into a 40-feature one-hot encoding for us\n",
    "#      already.\n",
    "# -Cover_Type: categorical for 7 different cover types (spruce/fir, lodgepole pine, ponderosa pine, cottonwood/willow,\n",
    "#      aspen, douglas-fir, krummholz)\n",
    "\n",
    "# Our task is to try and determine the cover type from the other features given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas                  as pd\n",
    "import math\n",
    "import numpy                   as np\n",
    "\n",
    "import sklearn.preprocessing   as sklpp\n",
    "import sklearn.decomposition   as skldecomp\n",
    "import sklearn.model_selection as sklms\n",
    "import sklearn.tree            as skltr\n",
    "import sklearn.svm             as sklsvm\n",
    "import sklearn.naive_bayes     as sklnb\n",
    "import sklearn.multiclass      as sklmc\n",
    "import sklearn.linear_model    as skllm\n",
    "import sklearn.neural_network  as sklnn\n",
    "\n",
    "import keras.models            as km\n",
    "import keras.layers            as kl\n",
    "import keras.callbacks         as kc\n",
    "\n",
    "import matplotlib.pyplot       as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Forest CoverType dataset\n",
      "\n",
      "\n",
      "1.\tTitle of Database:\n",
      "\n",
      "\tForest Covertype data\n",
      "\n",
      "\n",
      "2.\tSources:\n",
      "\n",
      "\t(a) Original owners of database:\n",
      "\t\tRemote Sensing and GIS Program\n",
      "\t\tDepartment of Forest Sciences\n",
      "\t\tCollege of Natural Resources\n",
      "\t\tColorado State University\n",
      "\t\tFort Collins, CO  80523\n",
      "\t\t(contact Jock A. Blackard, jblackard 'at' fs.fed.us\n",
      "\t\t      or Dr. Denis J. Dean, denis.dean 'at' utdallas.edu)\n",
      "\n",
      "\tNOTE:\tReuse of this database is unlimited with retention of \n",
      "\t\tcopyright notice for Jock A. Blackard and Colorado \n",
      "\t\tState University.\n",
      "\n",
      "\t(b) Donors of database:\n",
      "\t\tJock A. Blackard (jblackard 'at' fs.fed.us)\n",
      "\t\tGIS Coordinator\n",
      "\t\tUSFS - Forest Inventory & Analysis\n",
      "\t\tRocky Mountain Research Station\n",
      "\t\t507 25th Street\n",
      "\t\tOgden, UT 84401\n",
      "\n",
      "\t\tDr. Denis J. Dean (denis.dean 'at' utdallas.edu)\n",
      "\t\tProfessor\n",
      "\t\tProgram in Geography and Geospatial Sciences\n",
      "\t\tSchool of Economic, Political and Policy Sciences\n",
      "\t\t800 West Campbell Rd\n",
      "\t\tRichardson, TX  75080-3021 \n",
      "\t\t\n",
      "\t\tDr. Charles W. Anderson (anderson 'at' cs.colostate.edu)\n",
      "\t\tAssociate Professor\n",
      "\t\tDepartment of Computer Science\n",
      "\t\tColorado State University\n",
      "\t\tFort Collins, CO  80523  USA\n",
      "\n",
      "\t(c) Date donated:  August 1998\n",
      "\n",
      "\n",
      "3.\tPast Usage:\n",
      "\n",
      "\tBlackard, Jock A. and Denis J. Dean.  2000.  \"Comparative\n",
      "\t\tAccuracies of Artificial Neural Networks and Discriminant\n",
      "\t\tAnalysis in Predicting Forest Cover Types from Cartographic\n",
      "\t\tVariables.\"  Computers and Electronics in Agriculture \n",
      "\t\t24(3):131-151.\n",
      "\n",
      "\tBlackard, Jock A. and Denis J. Dean.  1998.  \"Comparative\n",
      "\t\tAccuracies of Neural Networks and Discriminant Analysis\n",
      "\t\tin Predicting Forest Cover Types from Cartographic \n",
      "\t\tVariables.\"  Second Southern Forestry GIS Conference.\n",
      "\t\tUniversity of Georgia.  Athens, GA.  Pages 189-199.\n",
      "\n",
      "\tBlackard, Jock A.  1998.  \"Comparison of Neural Networks and\n",
      "\t\tDiscriminant Analysis in Predicting Forest Cover Types.\"\n",
      "\t\tPh.D. dissertation.  Department of Forest Sciences.  \n",
      "\t\tColorado State University.  Fort Collins, Colorado.  \n",
      "\t\t165 pages.\n",
      "\n",
      "\tAbstract of dissertation:\n",
      "\t\tNatural resource managers responsible for developing \n",
      "\tecosystem management strategies require basic descriptive \n",
      "\tinformation including inventory data for forested lands to \n",
      "\tsupport their decision-making processes.  However, managers \n",
      "\tgenerally do not have this type of data for inholdings or \n",
      "\tneighboring lands that are outside their immediate \n",
      "\tjurisdiction.  One method of obtaining this information is \n",
      "\tthrough the use of predictive models.  \n",
      "\t\tTwo predictive models were examined in this study, a \n",
      "\tfeedforward neural network model and a more traditional \n",
      "\tstatistical model based on discriminant analysis.  The overall \n",
      "\tobjectives of this research were to first construct these two \n",
      "\tpredictive models, and second to compare and evaluate their \n",
      "\trespective classification accuracies when predicting forest \n",
      "\tcover types in undisturbed forests.  \n",
      "\t\tThe study area included four wilderness areas found in \n",
      "\tthe Roosevelt National Forest of northern Colorado.  A total \n",
      "\tof twelve cartographic measures were utilized as independent \n",
      "\tvariables in the predictive models, while seven major forest \n",
      "\tcover types were used as dependent variables.  Several subsets \n",
      "\tof these variables were examined to determine the best overall \n",
      "\tpredictive model.  \n",
      "\t\tFor each subset of cartographic variables examined in \n",
      "\tthis study, relative classification accuracies indicate the \n",
      "\tneural network approach outperformed the traditional \n",
      "\tdiscriminant analysis method in predicting forest cover types.  \n",
      "\tThe final neural network model had a higher absolute \n",
      "\tclassification accuracy (70.58%) than the final corresponding \n",
      "\tlinear discriminant analysis model(58.38%).  In support of these \n",
      "\tclassification results, thirty additional networks with randomly \n",
      "\tselected initial weights were derived.  From these networks, the \n",
      "\toverall mean absolute classification accuracy for the neural \n",
      "\tnetwork method was 70.52%, with a 95% confidence interval of \n",
      "\t70.26% to 70.80%.  Consequently, natural resource managers may \n",
      "\tutilize an alternative method of predicting forest cover types \n",
      "\tthat is both superior to the traditional statistical methods and \n",
      "\tadequate to support their decision-making processes for \n",
      "\tdeveloping ecosystem management strategies.\n",
      "\n",
      "\n",
      "\t-- Classification performance\n",
      "\t\t-- first 11,340 records used for training data subset\n",
      "\t\t-- next 3,780 records used for validation data subset\n",
      "\t\t-- last 565,892 records used for testing data subset\n",
      "\t\t-- 70% Neural Network (backpropagation)\n",
      "\t\t-- 58% Linear Discriminant Analysis\n",
      "\n",
      "\n",
      "4.\tRelevant Information Paragraph:\n",
      "\n",
      "\tPredicting forest cover type from cartographic variables only\n",
      "\t(no remotely sensed data).  The actual forest cover type for\n",
      "\ta given observation (30 x 30 meter cell) was determined from\n",
      "\tUS Forest Service (USFS) Region 2 Resource Information System \n",
      "\t(RIS) data.  Independent variables were derived from data\n",
      "\toriginally obtained from US Geological Survey (USGS) and\n",
      "\tUSFS data.  Data is in raw form (not scaled) and contains\n",
      "\tbinary (0 or 1) columns of data for qualitative independent\n",
      "\tvariables (wilderness areas and soil types).\n",
      "\n",
      "\tThis study area includes four wilderness areas located in the\n",
      "\tRoosevelt National Forest of northern Colorado.  These areas\n",
      "\trepresent forests with minimal human-caused disturbances,\n",
      "\tso that existing forest cover types are more a result of \n",
      "\tecological processes rather than forest management practices.\n",
      "\n",
      "\tSome background information for these four wilderness areas:  \n",
      "\tNeota (area 2) probably has the highest mean elevational value of \n",
      "\tthe 4 wilderness areas. Rawah (area 1) and Comanche Peak (area 3) \n",
      "\twould have a lower mean elevational value, while Cache la Poudre \n",
      "\t(area 4) would have the lowest mean elevational value. \n",
      "\n",
      "\tAs for primary major tree species in these areas, Neota would have \n",
      "\tspruce/fir (type 1), while Rawah and Comanche Peak would probably\n",
      "\thave lodgepole pine (type 2) as their primary species, followed by \n",
      "\tspruce/fir and aspen (type 5). Cache la Poudre would tend to have \n",
      "\tPonderosa pine (type 3), Douglas-fir (type 6), and \n",
      "\tcottonwood/willow (type 4).  \n",
      "\n",
      "\tThe Rawah and Comanche Peak areas would tend to be more typical of \n",
      "\tthe overall dataset than either the Neota or Cache la Poudre, due \n",
      "\tto their assortment of tree species and range of predictive \n",
      "\tvariable values (elevation, etc.)  Cache la Poudre would probably \n",
      "\tbe more unique than the others, due to its relatively low \n",
      "\televation range and species composition. \n",
      "\n",
      "\n",
      "5.\tNumber of instances (observations):  581,012\n",
      "\n",
      "\n",
      "6.\tNumber of Attributes:\t12 measures, but 54 columns of data\n",
      "\t\t\t\t(10 quantitative variables, 4 binary\n",
      "\t\t\t\twilderness areas and 40 binary\n",
      "\t\t\t\tsoil type variables)\n",
      "\n",
      "\n",
      "7.\tAttribute information:\n",
      "\n",
      "Given is the attribute name, attribute type, the measurement unit and\n",
      "a brief description.  The forest cover type is the classification \n",
      "problem.  The order of this listing corresponds to the order of \n",
      "numerals along the rows of the database.\n",
      "\n",
      "Name                                     Data Type    Measurement                       Description\n",
      "\n",
      "Elevation                               quantitative    meters                       Elevation in meters\n",
      "Aspect                                  quantitative    azimuth                      Aspect in degrees azimuth\n",
      "Slope                                   quantitative    degrees                      Slope in degrees\n",
      "Horizontal_Distance_To_Hydrology        quantitative    meters                       Horz Dist to nearest surface water features\n",
      "Vertical_Distance_To_Hydrology          quantitative    meters                       Vert Dist to nearest surface water features\n",
      "Horizontal_Distance_To_Roadways         quantitative    meters                       Horz Dist to nearest roadway\n",
      "Hillshade_9am                           quantitative    0 to 255 index               Hillshade index at 9am, summer solstice\n",
      "Hillshade_Noon                          quantitative    0 to 255 index               Hillshade index at noon, summer soltice\n",
      "Hillshade_3pm                           quantitative    0 to 255 index               Hillshade index at 3pm, summer solstice\n",
      "Horizontal_Distance_To_Fire_Points      quantitative    meters                       Horz Dist to nearest wildfire ignition points\n",
      "Wilderness_Area (4 binary columns)      qualitative     0 (absence) or 1 (presence)  Wilderness area designation\n",
      "Soil_Type (40 binary columns)           qualitative     0 (absence) or 1 (presence)  Soil Type designation\n",
      "Cover_Type (7 types)                    integer         1 to 7                       Forest Cover Type designation\n",
      "\n",
      "\n",
      "Code Designations:\n",
      "\n",
      "Wilderness Areas:  \t1 -- Rawah Wilderness Area\n",
      "                        2 -- Neota Wilderness Area\n",
      "                        3 -- Comanche Peak Wilderness Area\n",
      "                        4 -- Cache la Poudre Wilderness Area\n",
      "\n",
      "Soil Types:             1 to 40 : based on the USFS Ecological\n",
      "                        Landtype Units (ELUs) for this study area:\n",
      "\n",
      "  Study Code USFS ELU Code\t\t\tDescription\n",
      "\t 1\t   2702\t\tCathedral family - Rock outcrop complex, extremely stony.\n",
      "\t 2\t   2703\t\tVanet - Ratake families complex, very stony.\n",
      "\t 3\t   2704\t\tHaploborolis - Rock outcrop complex, rubbly.\n",
      "\t 4\t   2705\t\tRatake family - Rock outcrop complex, rubbly.\n",
      "\t 5\t   2706\t\tVanet family - Rock outcrop complex complex, rubbly.\n",
      "\t 6\t   2717\t\tVanet - Wetmore families - Rock outcrop complex, stony.\n",
      "\t 7\t   3501\t\tGothic family.\n",
      "\t 8\t   3502\t\tSupervisor - Limber families complex.\n",
      "\t 9\t   4201\t\tTroutville family, very stony.\n",
      "\t10\t   4703\t\tBullwark - Catamount families - Rock outcrop complex, rubbly.\n",
      "\t11\t   4704\t\tBullwark - Catamount families - Rock land complex, rubbly.\n",
      "\t12\t   4744\t\tLegault family - Rock land complex, stony.\n",
      "\t13\t   4758\t\tCatamount family - Rock land - Bullwark family complex, rubbly.\n",
      "\t14\t   5101\t\tPachic Argiborolis - Aquolis complex.\n",
      "\t15\t   5151\t\tunspecified in the USFS Soil and ELU Survey.\n",
      "\t16\t   6101\t\tCryaquolis - Cryoborolis complex.\n",
      "\t17\t   6102\t\tGateview family - Cryaquolis complex.\n",
      "\t18\t   6731\t\tRogert family, very stony.\n",
      "\t19\t   7101\t\tTypic Cryaquolis - Borohemists complex.\n",
      "\t20\t   7102\t\tTypic Cryaquepts - Typic Cryaquolls complex.\n",
      "\t21\t   7103\t\tTypic Cryaquolls - Leighcan family, till substratum complex.\n",
      "\t22\t   7201\t\tLeighcan family, till substratum, extremely bouldery.\n",
      "\t23\t   7202\t\tLeighcan family, till substratum - Typic Cryaquolls complex.\n",
      "\t24\t   7700\t\tLeighcan family, extremely stony.\n",
      "\t25\t   7701\t\tLeighcan family, warm, extremely stony.\n",
      "\t26\t   7702\t\tGranile - Catamount families complex, very stony.\n",
      "\t27\t   7709\t\tLeighcan family, warm - Rock outcrop complex, extremely stony.\n",
      "\t28\t   7710\t\tLeighcan family - Rock outcrop complex, extremely stony.\n",
      "\t29\t   7745\t\tComo - Legault families complex, extremely stony.\n",
      "\t30\t   7746\t\tComo family - Rock land - Legault family complex, extremely stony.\n",
      "\t31\t   7755\t\tLeighcan - Catamount families complex, extremely stony.\n",
      "\t32\t   7756\t\tCatamount family - Rock outcrop - Leighcan family complex, extremely stony.\n",
      "\t33\t   7757\t\tLeighcan - Catamount families - Rock outcrop complex, extremely stony.\n",
      "\t34\t   7790\t\tCryorthents - Rock land complex, extremely stony.\n",
      "\t35\t   8703\t\tCryumbrepts - Rock outcrop - Cryaquepts complex.\n",
      "\t36\t   8707\t\tBross family - Rock land - Cryumbrepts complex, extremely stony.\n",
      "\t37\t   8708\t\tRock outcrop - Cryumbrepts - Cryorthents complex, extremely stony.\n",
      "\t38\t   8771\t\tLeighcan - Moran families - Cryaquolls complex, extremely stony.\n",
      "\t39\t   8772\t\tMoran family - Cryorthents - Leighcan family complex, extremely stony.\n",
      "\t40\t   8776\t\tMoran family - Cryorthents - Rock land complex, extremely stony.\n",
      "\n",
      "        Note:   First digit:  climatic zone             Second digit:  geologic zones\n",
      "                1.  lower montane dry                   1.  alluvium\n",
      "                2.  lower montane                       2.  glacial\n",
      "                3.  montane dry                         3.  shale\n",
      "                4.  montane                             4.  sandstone\n",
      "                5.  montane dry and montane             5.  mixed sedimentary\n",
      "                6.  montane and subalpine               6.  unspecified in the USFS ELU Survey\n",
      "                7.  subalpine                           7.  igneous and metamorphic\n",
      "                8.  alpine                              8.  volcanic\n",
      "\n",
      "        The third and fourth ELU digits are unique to the mapping unit \n",
      "        and have no special meaning to the climatic or geologic zones.\n",
      "\n",
      "Forest Cover Type Classes:\t1 -- Spruce/Fir\n",
      "                                2 -- Lodgepole Pine\n",
      "                                3 -- Ponderosa Pine\n",
      "                                4 -- Cottonwood/Willow\n",
      "                                5 -- Aspen\n",
      "                                6 -- Douglas-fir\n",
      "                                7 -- Krummholz\n",
      "\n",
      "\n",
      "8.  Basic Summary Statistics for quantitative variables only\n",
      "\t(whole dataset -- thanks to Phil Rennert for the summary values):\n",
      "\n",
      "Name                                    Units             Mean   Std Dev\n",
      "Elevation                               meters          2959.36  279.98\n",
      "Aspect                                  azimuth          155.65  111.91\n",
      "Slope                                   degrees           14.10    7.49\n",
      "Horizontal_Distance_To_Hydrology        meters           269.43  212.55\n",
      "Vertical_Distance_To_Hydrology          meters            46.42   58.30\n",
      "Horizontal_Distance_To_Roadways         meters          2350.15 1559.25\n",
      "Hillshade_9am                           0 to 255 index   212.15   26.77\n",
      "Hillshade_Noon                          0 to 255 index   223.32   19.77\n",
      "Hillshade_3pm                           0 to 255 index   142.53   38.27\n",
      "Horizontal_Distance_To_Fire_Points      meters          1980.29 1324.19\n",
      "\n",
      "\n",
      "9.\tMissing Attribute Values:  None.\n",
      "\n",
      "\n",
      "10.\tClass distribution:\n",
      "\n",
      "           Number of records of Spruce-Fir:                211840 \n",
      "           Number of records of Lodgepole Pine:            283301 \n",
      "           Number of records of Ponderosa Pine:             35754 \n",
      "           Number of records of Cottonwood/Willow:           2747 \n",
      "           Number of records of Aspen:                       9493 \n",
      "           Number of records of Douglas-fir:                17367 \n",
      "           Number of records of Krummholz:                  20510  \n",
      "           Number of records of other:                          0  \n",
      "\t\t\n",
      "           Total records:                                  581012\n",
      "\n",
      "=====================================================================\n",
      "Jock A. Blackard\n",
      "08/28/1998 -- original text\n",
      "12/07/1999 -- updated mailing address, citations, background info \n",
      "\t\t  for study area, added summary statistics.\n",
      "=====================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('covtype.info', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        print(line[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elevation</th>\n",
       "      <th>aspect</th>\n",
       "      <th>slope</th>\n",
       "      <th>dist_to_hydro_horiz</th>\n",
       "      <th>dist_to_hydro_vert</th>\n",
       "      <th>dist_to_road_horiz</th>\n",
       "      <th>hillshade_9am</th>\n",
       "      <th>hillshade_noon</th>\n",
       "      <th>hillshade_3pm</th>\n",
       "      <th>dist_to_fire_horiz</th>\n",
       "      <th>...</th>\n",
       "      <th>soil_type_7756</th>\n",
       "      <th>soil_type_7757</th>\n",
       "      <th>soil_type_7790</th>\n",
       "      <th>soil_type_8703</th>\n",
       "      <th>soil_type_8707</th>\n",
       "      <th>soil_type_8708</th>\n",
       "      <th>soil_type_8771</th>\n",
       "      <th>soil_type_8772</th>\n",
       "      <th>soil_type_8776</th>\n",
       "      <th>covertype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67232</th>\n",
       "      <td>3031</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>741</td>\n",
       "      <td>66</td>\n",
       "      <td>5671</td>\n",
       "      <td>213</td>\n",
       "      <td>231</td>\n",
       "      <td>156</td>\n",
       "      <td>5810</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187758</th>\n",
       "      <td>3180</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>402</td>\n",
       "      <td>77</td>\n",
       "      <td>4119</td>\n",
       "      <td>215</td>\n",
       "      <td>234</td>\n",
       "      <td>156</td>\n",
       "      <td>987</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205893</th>\n",
       "      <td>3238</td>\n",
       "      <td>75</td>\n",
       "      <td>13</td>\n",
       "      <td>430</td>\n",
       "      <td>89</td>\n",
       "      <td>4214</td>\n",
       "      <td>235</td>\n",
       "      <td>216</td>\n",
       "      <td>110</td>\n",
       "      <td>1188</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265094</th>\n",
       "      <td>2063</td>\n",
       "      <td>329</td>\n",
       "      <td>31</td>\n",
       "      <td>67</td>\n",
       "      <td>47</td>\n",
       "      <td>270</td>\n",
       "      <td>131</td>\n",
       "      <td>186</td>\n",
       "      <td>186</td>\n",
       "      <td>404</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89668</th>\n",
       "      <td>2968</td>\n",
       "      <td>251</td>\n",
       "      <td>12</td>\n",
       "      <td>534</td>\n",
       "      <td>65</td>\n",
       "      <td>5736</td>\n",
       "      <td>193</td>\n",
       "      <td>248</td>\n",
       "      <td>193</td>\n",
       "      <td>3684</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528948</th>\n",
       "      <td>3264</td>\n",
       "      <td>328</td>\n",
       "      <td>19</td>\n",
       "      <td>421</td>\n",
       "      <td>113</td>\n",
       "      <td>2873</td>\n",
       "      <td>170</td>\n",
       "      <td>214</td>\n",
       "      <td>182</td>\n",
       "      <td>551</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559457</th>\n",
       "      <td>2617</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>3391</td>\n",
       "      <td>213</td>\n",
       "      <td>221</td>\n",
       "      <td>144</td>\n",
       "      <td>2765</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344516</th>\n",
       "      <td>2816</td>\n",
       "      <td>104</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>15</td>\n",
       "      <td>1239</td>\n",
       "      <td>226</td>\n",
       "      <td>234</td>\n",
       "      <td>143</td>\n",
       "      <td>1959</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82863</th>\n",
       "      <td>2991</td>\n",
       "      <td>90</td>\n",
       "      <td>9</td>\n",
       "      <td>247</td>\n",
       "      <td>29</td>\n",
       "      <td>3275</td>\n",
       "      <td>233</td>\n",
       "      <td>227</td>\n",
       "      <td>125</td>\n",
       "      <td>6187</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14848</th>\n",
       "      <td>2682</td>\n",
       "      <td>163</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>47</td>\n",
       "      <td>3197</td>\n",
       "      <td>234</td>\n",
       "      <td>242</td>\n",
       "      <td>131</td>\n",
       "      <td>1838</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454056</th>\n",
       "      <td>3099</td>\n",
       "      <td>107</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1681</td>\n",
       "      <td>236</td>\n",
       "      <td>229</td>\n",
       "      <td>124</td>\n",
       "      <td>3155</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279503</th>\n",
       "      <td>2255</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>120</td>\n",
       "      <td>58</td>\n",
       "      <td>1557</td>\n",
       "      <td>130</td>\n",
       "      <td>124</td>\n",
       "      <td>104</td>\n",
       "      <td>949</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313872</th>\n",
       "      <td>2952</td>\n",
       "      <td>338</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>2370</td>\n",
       "      <td>196</td>\n",
       "      <td>225</td>\n",
       "      <td>167</td>\n",
       "      <td>872</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413881</th>\n",
       "      <td>2744</td>\n",
       "      <td>178</td>\n",
       "      <td>29</td>\n",
       "      <td>190</td>\n",
       "      <td>78</td>\n",
       "      <td>2017</td>\n",
       "      <td>218</td>\n",
       "      <td>241</td>\n",
       "      <td>134</td>\n",
       "      <td>2268</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491309</th>\n",
       "      <td>3031</td>\n",
       "      <td>86</td>\n",
       "      <td>19</td>\n",
       "      <td>541</td>\n",
       "      <td>197</td>\n",
       "      <td>579</td>\n",
       "      <td>244</td>\n",
       "      <td>204</td>\n",
       "      <td>81</td>\n",
       "      <td>1020</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>2699</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>60</td>\n",
       "      <td>29</td>\n",
       "      <td>1518</td>\n",
       "      <td>201</td>\n",
       "      <td>210</td>\n",
       "      <td>145</td>\n",
       "      <td>1678</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134969</th>\n",
       "      <td>2847</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>301</td>\n",
       "      <td>49</td>\n",
       "      <td>2016</td>\n",
       "      <td>213</td>\n",
       "      <td>226</td>\n",
       "      <td>150</td>\n",
       "      <td>1684</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400924</th>\n",
       "      <td>3190</td>\n",
       "      <td>358</td>\n",
       "      <td>15</td>\n",
       "      <td>60</td>\n",
       "      <td>11</td>\n",
       "      <td>1691</td>\n",
       "      <td>195</td>\n",
       "      <td>210</td>\n",
       "      <td>152</td>\n",
       "      <td>424</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565218</th>\n",
       "      <td>2613</td>\n",
       "      <td>33</td>\n",
       "      <td>17</td>\n",
       "      <td>190</td>\n",
       "      <td>35</td>\n",
       "      <td>1048</td>\n",
       "      <td>214</td>\n",
       "      <td>199</td>\n",
       "      <td>116</td>\n",
       "      <td>1560</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196095</th>\n",
       "      <td>3096</td>\n",
       "      <td>305</td>\n",
       "      <td>13</td>\n",
       "      <td>268</td>\n",
       "      <td>63</td>\n",
       "      <td>3427</td>\n",
       "      <td>182</td>\n",
       "      <td>232</td>\n",
       "      <td>190</td>\n",
       "      <td>618</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546984</th>\n",
       "      <td>3226</td>\n",
       "      <td>334</td>\n",
       "      <td>16</td>\n",
       "      <td>255</td>\n",
       "      <td>50</td>\n",
       "      <td>4489</td>\n",
       "      <td>181</td>\n",
       "      <td>217</td>\n",
       "      <td>174</td>\n",
       "      <td>750</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109803</th>\n",
       "      <td>2862</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>277</td>\n",
       "      <td>31</td>\n",
       "      <td>2317</td>\n",
       "      <td>222</td>\n",
       "      <td>219</td>\n",
       "      <td>131</td>\n",
       "      <td>2323</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93335</th>\n",
       "      <td>2869</td>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>532</td>\n",
       "      <td>20</td>\n",
       "      <td>2731</td>\n",
       "      <td>223</td>\n",
       "      <td>230</td>\n",
       "      <td>143</td>\n",
       "      <td>2871</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399501</th>\n",
       "      <td>2728</td>\n",
       "      <td>221</td>\n",
       "      <td>14</td>\n",
       "      <td>361</td>\n",
       "      <td>145</td>\n",
       "      <td>2105</td>\n",
       "      <td>202</td>\n",
       "      <td>253</td>\n",
       "      <td>185</td>\n",
       "      <td>2529</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19197</th>\n",
       "      <td>2762</td>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>295</td>\n",
       "      <td>95</td>\n",
       "      <td>2695</td>\n",
       "      <td>220</td>\n",
       "      <td>226</td>\n",
       "      <td>142</td>\n",
       "      <td>6675</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550322</th>\n",
       "      <td>3424</td>\n",
       "      <td>302</td>\n",
       "      <td>13</td>\n",
       "      <td>170</td>\n",
       "      <td>30</td>\n",
       "      <td>1994</td>\n",
       "      <td>182</td>\n",
       "      <td>233</td>\n",
       "      <td>191</td>\n",
       "      <td>3555</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199088</th>\n",
       "      <td>3030</td>\n",
       "      <td>148</td>\n",
       "      <td>6</td>\n",
       "      <td>247</td>\n",
       "      <td>50</td>\n",
       "      <td>1207</td>\n",
       "      <td>228</td>\n",
       "      <td>240</td>\n",
       "      <td>145</td>\n",
       "      <td>2405</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187910</th>\n",
       "      <td>3243</td>\n",
       "      <td>108</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>4295</td>\n",
       "      <td>223</td>\n",
       "      <td>236</td>\n",
       "      <td>149</td>\n",
       "      <td>2247</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287184</th>\n",
       "      <td>3298</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>134</td>\n",
       "      <td>9</td>\n",
       "      <td>4039</td>\n",
       "      <td>216</td>\n",
       "      <td>222</td>\n",
       "      <td>142</td>\n",
       "      <td>3901</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78271</th>\n",
       "      <td>2555</td>\n",
       "      <td>140</td>\n",
       "      <td>12</td>\n",
       "      <td>108</td>\n",
       "      <td>32</td>\n",
       "      <td>780</td>\n",
       "      <td>238</td>\n",
       "      <td>236</td>\n",
       "      <td>126</td>\n",
       "      <td>182</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30920</th>\n",
       "      <td>2952</td>\n",
       "      <td>305</td>\n",
       "      <td>6</td>\n",
       "      <td>446</td>\n",
       "      <td>125</td>\n",
       "      <td>4891</td>\n",
       "      <td>204</td>\n",
       "      <td>237</td>\n",
       "      <td>172</td>\n",
       "      <td>5029</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94705</th>\n",
       "      <td>2643</td>\n",
       "      <td>136</td>\n",
       "      <td>19</td>\n",
       "      <td>60</td>\n",
       "      <td>-8</td>\n",
       "      <td>866</td>\n",
       "      <td>246</td>\n",
       "      <td>229</td>\n",
       "      <td>104</td>\n",
       "      <td>1972</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415851</th>\n",
       "      <td>2797</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1889</td>\n",
       "      <td>221</td>\n",
       "      <td>231</td>\n",
       "      <td>146</td>\n",
       "      <td>2375</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548866</th>\n",
       "      <td>3156</td>\n",
       "      <td>179</td>\n",
       "      <td>19</td>\n",
       "      <td>210</td>\n",
       "      <td>65</td>\n",
       "      <td>3303</td>\n",
       "      <td>224</td>\n",
       "      <td>248</td>\n",
       "      <td>147</td>\n",
       "      <td>671</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369440</th>\n",
       "      <td>2604</td>\n",
       "      <td>167</td>\n",
       "      <td>4</td>\n",
       "      <td>306</td>\n",
       "      <td>59</td>\n",
       "      <td>1557</td>\n",
       "      <td>223</td>\n",
       "      <td>241</td>\n",
       "      <td>153</td>\n",
       "      <td>1727</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167080</th>\n",
       "      <td>2963</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>127</td>\n",
       "      <td>11</td>\n",
       "      <td>2114</td>\n",
       "      <td>218</td>\n",
       "      <td>220</td>\n",
       "      <td>137</td>\n",
       "      <td>1371</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433307</th>\n",
       "      <td>3306</td>\n",
       "      <td>288</td>\n",
       "      <td>12</td>\n",
       "      <td>360</td>\n",
       "      <td>31</td>\n",
       "      <td>2592</td>\n",
       "      <td>187</td>\n",
       "      <td>239</td>\n",
       "      <td>192</td>\n",
       "      <td>771</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215836</th>\n",
       "      <td>3224</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>3189</td>\n",
       "      <td>217</td>\n",
       "      <td>233</td>\n",
       "      <td>153</td>\n",
       "      <td>2167</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488158</th>\n",
       "      <td>2927</td>\n",
       "      <td>318</td>\n",
       "      <td>24</td>\n",
       "      <td>376</td>\n",
       "      <td>168</td>\n",
       "      <td>492</td>\n",
       "      <td>151</td>\n",
       "      <td>211</td>\n",
       "      <td>196</td>\n",
       "      <td>1215</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309957</th>\n",
       "      <td>3015</td>\n",
       "      <td>77</td>\n",
       "      <td>12</td>\n",
       "      <td>67</td>\n",
       "      <td>9</td>\n",
       "      <td>2942</td>\n",
       "      <td>235</td>\n",
       "      <td>218</td>\n",
       "      <td>113</td>\n",
       "      <td>1503</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12766</th>\n",
       "      <td>2247</td>\n",
       "      <td>133</td>\n",
       "      <td>27</td>\n",
       "      <td>108</td>\n",
       "      <td>59</td>\n",
       "      <td>1252</td>\n",
       "      <td>251</td>\n",
       "      <td>215</td>\n",
       "      <td>74</td>\n",
       "      <td>1041</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382707</th>\n",
       "      <td>3240</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>210</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>217</td>\n",
       "      <td>229</td>\n",
       "      <td>149</td>\n",
       "      <td>1071</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347764</th>\n",
       "      <td>3028</td>\n",
       "      <td>60</td>\n",
       "      <td>27</td>\n",
       "      <td>90</td>\n",
       "      <td>-5</td>\n",
       "      <td>626</td>\n",
       "      <td>229</td>\n",
       "      <td>174</td>\n",
       "      <td>60</td>\n",
       "      <td>1276</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347091</th>\n",
       "      <td>2629</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>247</td>\n",
       "      <td>81</td>\n",
       "      <td>426</td>\n",
       "      <td>193</td>\n",
       "      <td>194</td>\n",
       "      <td>133</td>\n",
       "      <td>1333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459266</th>\n",
       "      <td>3274</td>\n",
       "      <td>127</td>\n",
       "      <td>10</td>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "      <td>1869</td>\n",
       "      <td>237</td>\n",
       "      <td>234</td>\n",
       "      <td>126</td>\n",
       "      <td>2941</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6715</th>\n",
       "      <td>2735</td>\n",
       "      <td>60</td>\n",
       "      <td>8</td>\n",
       "      <td>524</td>\n",
       "      <td>101</td>\n",
       "      <td>570</td>\n",
       "      <td>227</td>\n",
       "      <td>223</td>\n",
       "      <td>131</td>\n",
       "      <td>362</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38404</th>\n",
       "      <td>2777</td>\n",
       "      <td>355</td>\n",
       "      <td>8</td>\n",
       "      <td>85</td>\n",
       "      <td>13</td>\n",
       "      <td>3046</td>\n",
       "      <td>207</td>\n",
       "      <td>226</td>\n",
       "      <td>157</td>\n",
       "      <td>5382</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540509</th>\n",
       "      <td>3306</td>\n",
       "      <td>272</td>\n",
       "      <td>17</td>\n",
       "      <td>365</td>\n",
       "      <td>88</td>\n",
       "      <td>4094</td>\n",
       "      <td>174</td>\n",
       "      <td>243</td>\n",
       "      <td>208</td>\n",
       "      <td>1764</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490873</th>\n",
       "      <td>2997</td>\n",
       "      <td>346</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>234</td>\n",
       "      <td>196</td>\n",
       "      <td>220</td>\n",
       "      <td>163</td>\n",
       "      <td>1722</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199928</th>\n",
       "      <td>3013</td>\n",
       "      <td>147</td>\n",
       "      <td>10</td>\n",
       "      <td>240</td>\n",
       "      <td>33</td>\n",
       "      <td>1248</td>\n",
       "      <td>234</td>\n",
       "      <td>239</td>\n",
       "      <td>136</td>\n",
       "      <td>2464</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109789</th>\n",
       "      <td>2902</td>\n",
       "      <td>35</td>\n",
       "      <td>17</td>\n",
       "      <td>607</td>\n",
       "      <td>53</td>\n",
       "      <td>2613</td>\n",
       "      <td>216</td>\n",
       "      <td>200</td>\n",
       "      <td>114</td>\n",
       "      <td>1996</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425319</th>\n",
       "      <td>3254</td>\n",
       "      <td>197</td>\n",
       "      <td>24</td>\n",
       "      <td>362</td>\n",
       "      <td>86</td>\n",
       "      <td>531</td>\n",
       "      <td>206</td>\n",
       "      <td>252</td>\n",
       "      <td>168</td>\n",
       "      <td>1080</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308458</th>\n",
       "      <td>2974</td>\n",
       "      <td>29</td>\n",
       "      <td>24</td>\n",
       "      <td>134</td>\n",
       "      <td>44</td>\n",
       "      <td>2016</td>\n",
       "      <td>204</td>\n",
       "      <td>180</td>\n",
       "      <td>102</td>\n",
       "      <td>2350</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36086</th>\n",
       "      <td>2714</td>\n",
       "      <td>133</td>\n",
       "      <td>10</td>\n",
       "      <td>134</td>\n",
       "      <td>31</td>\n",
       "      <td>2429</td>\n",
       "      <td>236</td>\n",
       "      <td>235</td>\n",
       "      <td>129</td>\n",
       "      <td>4858</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366927</th>\n",
       "      <td>3095</td>\n",
       "      <td>133</td>\n",
       "      <td>9</td>\n",
       "      <td>134</td>\n",
       "      <td>19</td>\n",
       "      <td>1798</td>\n",
       "      <td>235</td>\n",
       "      <td>236</td>\n",
       "      <td>131</td>\n",
       "      <td>2164</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475426</th>\n",
       "      <td>3210</td>\n",
       "      <td>228</td>\n",
       "      <td>6</td>\n",
       "      <td>201</td>\n",
       "      <td>43</td>\n",
       "      <td>3027</td>\n",
       "      <td>212</td>\n",
       "      <td>245</td>\n",
       "      <td>171</td>\n",
       "      <td>1020</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513372</th>\n",
       "      <td>3300</td>\n",
       "      <td>302</td>\n",
       "      <td>9</td>\n",
       "      <td>646</td>\n",
       "      <td>116</td>\n",
       "      <td>638</td>\n",
       "      <td>195</td>\n",
       "      <td>236</td>\n",
       "      <td>181</td>\n",
       "      <td>1233</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76267</th>\n",
       "      <td>2588</td>\n",
       "      <td>38</td>\n",
       "      <td>10</td>\n",
       "      <td>324</td>\n",
       "      <td>65</td>\n",
       "      <td>870</td>\n",
       "      <td>220</td>\n",
       "      <td>217</td>\n",
       "      <td>131</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190830</th>\n",
       "      <td>3226</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>382</td>\n",
       "      <td>30</td>\n",
       "      <td>5892</td>\n",
       "      <td>218</td>\n",
       "      <td>239</td>\n",
       "      <td>157</td>\n",
       "      <td>1790</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268198</th>\n",
       "      <td>2162</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>42</td>\n",
       "      <td>20</td>\n",
       "      <td>1129</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "      <td>132</td>\n",
       "      <td>466</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29051 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        elevation  aspect  slope  dist_to_hydro_horiz  dist_to_hydro_vert  \\\n",
       "67232        3031       0      5                  741                  66   \n",
       "187758       3180       0      3                  402                  77   \n",
       "205893       3238      75     13                  430                  89   \n",
       "265094       2063     329     31                   67                  47   \n",
       "89668        2968     251     12                  534                  65   \n",
       "528948       3264     328     19                  421                 113   \n",
       "559457       2617      18      9                   42                   2   \n",
       "344516       2816     104      4                  175                  15   \n",
       "82863        2991      90      9                  247                  29   \n",
       "14848        2682     163     18                  242                  47   \n",
       "454056       3099     107      9                   30                   1   \n",
       "279503       2255       4     42                  120                  58   \n",
       "313872       2952     338     11                   30                   6   \n",
       "413881       2744     178     29                  190                  78   \n",
       "491309       3031      86     19                  541                 197   \n",
       "2195         2699       6     15                   60                  29   \n",
       "134969       2847      12      7                  301                  49   \n",
       "400924       3190     358     15                   60                  11   \n",
       "565218       2613      33     17                  190                  35   \n",
       "196095       3096     305     13                  268                  63   \n",
       "546984       3226     334     16                  255                  50   \n",
       "109803       2862      43     10                  277                  31   \n",
       "93335        2869      58      4                  532                  20   \n",
       "399501       2728     221     14                  361                 145   \n",
       "19197        2762      36      6                  295                  95   \n",
       "550322       3424     302     13                  170                  30   \n",
       "199088       3030     148      6                  247                  50   \n",
       "187910       3243     108      2                  300                   0   \n",
       "287184       3298      24      9                  134                   9   \n",
       "78271        2555     140     12                  108                  32   \n",
       "...           ...     ...    ...                  ...                 ...   \n",
       "30920        2952     305      6                  446                 125   \n",
       "94705        2643     136     19                   60                  -8   \n",
       "415851       2797      45      4                   30                   2   \n",
       "548866       3156     179     19                  210                  65   \n",
       "369440       2604     167      4                  306                  59   \n",
       "167080       2963      32      9                  127                  11   \n",
       "433307       3306     288     12                  360                  31   \n",
       "215836       3224      18      3                   42                   0   \n",
       "488158       2927     318     24                  376                 168   \n",
       "309957       3015      77     12                   67                   9   \n",
       "12766        2247     133     27                  108                  59   \n",
       "382707       3240      22      5                  210                   6   \n",
       "347764       3028      60     27                   90                  -5   \n",
       "347091       2629      10     20                  247                  81   \n",
       "459266       3274     127     10                   42                   7   \n",
       "6715         2735      60      8                  524                 101   \n",
       "38404        2777     355      8                   85                  13   \n",
       "540509       3306     272     17                  365                  88   \n",
       "490873       2997     346     12                   30                   6   \n",
       "199928       3013     147     10                  240                  33   \n",
       "109789       2902      35     17                  607                  53   \n",
       "425319       3254     197     24                  362                  86   \n",
       "308458       2974      29     24                  134                  44   \n",
       "36086        2714     133     10                  134                  31   \n",
       "366927       3095     133      9                  134                  19   \n",
       "475426       3210     228      6                  201                  43   \n",
       "513372       3300     302      9                  646                 116   \n",
       "76267        2588      38     10                  324                  65   \n",
       "190830       3226     198      1                  382                  30   \n",
       "268198       2162       8     23                   42                  20   \n",
       "\n",
       "        dist_to_road_horiz  hillshade_9am  hillshade_noon  hillshade_3pm  \\\n",
       "67232                 5671            213             231            156   \n",
       "187758                4119            215             234            156   \n",
       "205893                4214            235             216            110   \n",
       "265094                 270            131             186            186   \n",
       "89668                 5736            193             248            193   \n",
       "528948                2873            170             214            182   \n",
       "559457                3391            213             221            144   \n",
       "344516                1239            226             234            143   \n",
       "82863                 3275            233             227            125   \n",
       "14848                 3197            234             242            131   \n",
       "454056                1681            236             229            124   \n",
       "279503                1557            130             124            104   \n",
       "313872                2370            196             225            167   \n",
       "413881                2017            218             241            134   \n",
       "491309                 579            244             204             81   \n",
       "2195                  1518            201             210            145   \n",
       "134969                2016            213             226            150   \n",
       "400924                1691            195             210            152   \n",
       "565218                1048            214             199            116   \n",
       "196095                3427            182             232            190   \n",
       "546984                4489            181             217            174   \n",
       "109803                2317            222             219            131   \n",
       "93335                 2731            223             230            143   \n",
       "399501                2105            202             253            185   \n",
       "19197                 2695            220             226            142   \n",
       "550322                1994            182             233            191   \n",
       "199088                1207            228             240            145   \n",
       "187910                4295            223             236            149   \n",
       "287184                4039            216             222            142   \n",
       "78271                  780            238             236            126   \n",
       "...                    ...            ...             ...            ...   \n",
       "30920                 4891            204             237            172   \n",
       "94705                  866            246             229            104   \n",
       "415851                1889            221             231            146   \n",
       "548866                3303            224             248            147   \n",
       "369440                1557            223             241            153   \n",
       "167080                2114            218             220            137   \n",
       "433307                2592            187             239            192   \n",
       "215836                3189            217             233            153   \n",
       "488158                 492            151             211            196   \n",
       "309957                2942            235             218            113   \n",
       "12766                 1252            251             215             74   \n",
       "382707                   0            217             229            149   \n",
       "347764                 626            229             174             60   \n",
       "347091                 426            193             194            133   \n",
       "459266                1869            237             234            126   \n",
       "6715                   570            227             223            131   \n",
       "38404                 3046            207             226            157   \n",
       "540509                4094            174             243            208   \n",
       "490873                 234            196             220            163   \n",
       "199928                1248            234             239            136   \n",
       "109789                2613            216             200            114   \n",
       "425319                 531            206             252            168   \n",
       "308458                2016            204             180            102   \n",
       "36086                 2429            236             235            129   \n",
       "366927                1798            235             236            131   \n",
       "475426                3027            212             245            171   \n",
       "513372                 638            195             236            181   \n",
       "76267                  870            220             217            131   \n",
       "190830                5892            218             239            157   \n",
       "268198                1129            186             187            132   \n",
       "\n",
       "        dist_to_fire_horiz    ...      soil_type_7756  soil_type_7757  \\\n",
       "67232                 5810    ...                   0               0   \n",
       "187758                 987    ...                   0               0   \n",
       "205893                1188    ...                   0               0   \n",
       "265094                 404    ...                   0               0   \n",
       "89668                 3684    ...                   0               0   \n",
       "528948                 551    ...                   0               1   \n",
       "559457                2765    ...                   0               0   \n",
       "344516                1959    ...                   0               0   \n",
       "82863                 6187    ...                   0               0   \n",
       "14848                 1838    ...                   0               0   \n",
       "454056                3155    ...                   0               0   \n",
       "279503                 949    ...                   0               0   \n",
       "313872                 872    ...                   0               0   \n",
       "413881                2268    ...                   0               0   \n",
       "491309                1020    ...                   0               1   \n",
       "2195                  1678    ...                   0               0   \n",
       "134969                1684    ...                   0               0   \n",
       "400924                 424    ...                   0               0   \n",
       "565218                1560    ...                   0               0   \n",
       "196095                 618    ...                   0               0   \n",
       "546984                 750    ...                   1               0   \n",
       "109803                2323    ...                   0               0   \n",
       "93335                 2871    ...                   0               0   \n",
       "399501                2529    ...                   0               0   \n",
       "19197                 6675    ...                   0               0   \n",
       "550322                3555    ...                   1               0   \n",
       "199088                2405    ...                   0               0   \n",
       "187910                2247    ...                   0               0   \n",
       "287184                3901    ...                   0               0   \n",
       "78271                  182    ...                   0               0   \n",
       "...                    ...    ...                 ...             ...   \n",
       "30920                 5029    ...                   0               0   \n",
       "94705                 1972    ...                   0               0   \n",
       "415851                2375    ...                   0               0   \n",
       "548866                 671    ...                   0               0   \n",
       "369440                1727    ...                   0               0   \n",
       "167080                1371    ...                   0               0   \n",
       "433307                 771    ...                   1               0   \n",
       "215836                2167    ...                   0               0   \n",
       "488158                1215    ...                   0               1   \n",
       "309957                1503    ...                   1               0   \n",
       "12766                 1041    ...                   0               0   \n",
       "382707                1071    ...                   1               0   \n",
       "347764                1276    ...                   0               0   \n",
       "347091                1333    ...                   0               0   \n",
       "459266                2941    ...                   0               0   \n",
       "6715                   362    ...                   0               0   \n",
       "38404                 5382    ...                   0               0   \n",
       "540509                1764    ...                   0               0   \n",
       "490873                1722    ...                   0               0   \n",
       "199928                2464    ...                   0               0   \n",
       "109789                1996    ...                   0               0   \n",
       "425319                1080    ...                   0               0   \n",
       "308458                2350    ...                   1               0   \n",
       "36086                 4858    ...                   0               0   \n",
       "366927                2164    ...                   0               0   \n",
       "475426                1020    ...                   1               0   \n",
       "513372                1233    ...                   0               0   \n",
       "76267                   67    ...                   0               0   \n",
       "190830                1790    ...                   0               0   \n",
       "268198                 466    ...                   0               0   \n",
       "\n",
       "        soil_type_7790  soil_type_8703  soil_type_8707  soil_type_8708  \\\n",
       "67232                0               0               0               0   \n",
       "187758               0               0               0               0   \n",
       "205893               0               0               0               0   \n",
       "265094               0               0               0               0   \n",
       "89668                0               0               0               0   \n",
       "528948               0               0               0               0   \n",
       "559457               0               0               0               0   \n",
       "344516               0               0               0               0   \n",
       "82863                0               0               0               0   \n",
       "14848                0               0               0               0   \n",
       "454056               0               0               0               0   \n",
       "279503               0               0               0               0   \n",
       "313872               0               0               0               0   \n",
       "413881               0               0               0               0   \n",
       "491309               0               0               0               0   \n",
       "2195                 0               0               0               0   \n",
       "134969               0               0               0               0   \n",
       "400924               0               0               0               0   \n",
       "565218               0               0               0               0   \n",
       "196095               0               0               0               0   \n",
       "546984               0               0               0               0   \n",
       "109803               0               0               0               0   \n",
       "93335                0               0               0               0   \n",
       "399501               0               0               0               0   \n",
       "19197                0               0               0               0   \n",
       "550322               0               0               0               0   \n",
       "199088               0               0               0               0   \n",
       "187910               0               0               0               0   \n",
       "287184               0               0               0               0   \n",
       "78271                0               0               0               0   \n",
       "...                ...             ...             ...             ...   \n",
       "30920                0               0               0               0   \n",
       "94705                0               0               0               0   \n",
       "415851               0               0               0               0   \n",
       "548866               1               0               0               0   \n",
       "369440               0               0               0               0   \n",
       "167080               0               0               0               0   \n",
       "433307               0               0               0               0   \n",
       "215836               0               0               0               0   \n",
       "488158               0               0               0               0   \n",
       "309957               0               0               0               0   \n",
       "12766                0               0               0               0   \n",
       "382707               0               0               0               0   \n",
       "347764               0               0               0               0   \n",
       "347091               0               0               0               0   \n",
       "459266               0               0               0               0   \n",
       "6715                 0               0               0               0   \n",
       "38404                0               0               0               0   \n",
       "540509               0               0               0               0   \n",
       "490873               0               0               0               0   \n",
       "199928               0               0               0               0   \n",
       "109789               0               0               0               0   \n",
       "425319               0               0               0               0   \n",
       "308458               0               0               0               0   \n",
       "36086                0               0               0               0   \n",
       "366927               0               0               0               0   \n",
       "475426               0               0               0               0   \n",
       "513372               0               0               0               0   \n",
       "76267                0               0               0               0   \n",
       "190830               0               0               0               0   \n",
       "268198               0               0               0               0   \n",
       "\n",
       "        soil_type_8771  soil_type_8772  soil_type_8776  covertype  \n",
       "67232                0               0               0          2  \n",
       "187758               0               0               0          2  \n",
       "205893               0               0               0          2  \n",
       "265094               0               0               0          6  \n",
       "89668                0               0               0          2  \n",
       "528948               0               0               0          1  \n",
       "559457               0               0               0          1  \n",
       "344516               0               0               0          2  \n",
       "82863                0               0               0          2  \n",
       "14848                0               0               0          5  \n",
       "454056               0               0               0          1  \n",
       "279503               0               0               0          3  \n",
       "313872               0               0               0          1  \n",
       "413881               0               0               0          3  \n",
       "491309               0               0               0          1  \n",
       "2195                 0               0               0          6  \n",
       "134969               0               0               0          2  \n",
       "400924               0               0               0          1  \n",
       "565218               0               0               0          2  \n",
       "196095               0               0               0          1  \n",
       "546984               0               0               0          1  \n",
       "109803               0               0               0          2  \n",
       "93335                0               0               0          2  \n",
       "399501               0               0               0          3  \n",
       "19197                0               0               0          1  \n",
       "550322               0               0               0          1  \n",
       "199088               0               0               0          2  \n",
       "187910               0               0               0          1  \n",
       "287184               1               0               0          7  \n",
       "78271                0               0               0          2  \n",
       "...                ...             ...             ...        ...  \n",
       "30920                0               0               0          2  \n",
       "94705                0               0               0          2  \n",
       "415851               0               0               0          2  \n",
       "548866               0               0               0          2  \n",
       "369440               0               0               0          3  \n",
       "167080               0               0               0          1  \n",
       "433307               0               0               0          1  \n",
       "215836               1               0               0          7  \n",
       "488158               0               0               0          1  \n",
       "309957               0               0               0          1  \n",
       "12766                0               0               0          4  \n",
       "382707               0               0               0          1  \n",
       "347764               0               0               0          1  \n",
       "347091               0               0               0          6  \n",
       "459266               0               0               0          1  \n",
       "6715                 0               0               0          3  \n",
       "38404                0               0               0          2  \n",
       "540509               0               0               0          1  \n",
       "490873               0               0               0          1  \n",
       "199928               0               0               0          2  \n",
       "109789               0               0               0          2  \n",
       "425319               0               0               0          1  \n",
       "308458               0               0               0          1  \n",
       "36086                0               0               0          2  \n",
       "366927               0               0               0          1  \n",
       "475426               0               0               0          2  \n",
       "513372               0               0               0          1  \n",
       "76267                0               0               0          2  \n",
       "190830               0               0               0          1  \n",
       "268198               0               0               0          3  \n",
       "\n",
       "[29051 rows x 55 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('covtype.data')\n",
    "# Was running slow with all ~600k data points, so pare it down. That should still be fine.\n",
    "data = data.sample(frac = 0.05, random_state = 200)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Even though the CSV has features like soil type encoded as one-hot, we still need to do some data pre-processing.\n",
    "# For one, the aspect is an angle from [0, 360). https://en.wikipedia.org/wiki/Aspect_(geography)\n",
    "# In that encoding, there is no sense of the angle 359 being very close to 0.\n",
    "# Instead, I want to use a vector encoding with each aspect vector being a unit vector. Then the vector for 359 will\n",
    "# be close to the vector for 0.\n",
    "\n",
    "data['aspect_x'] = data.aspect.map(lambda aspect: math.cos(aspect))\n",
    "data['aspect_y'] = data.aspect.map(lambda aspect: math.sin(aspect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29051, 56)\n"
     ]
    }
   ],
   "source": [
    "# Split into X and y\n",
    "data = data.drop(['aspect'], axis = 1)\n",
    "data = np.matrix(data)\n",
    "print(data.shape)\n",
    "\n",
    "# Cut out old aspect and the class\n",
    "X_slice = list(range(53)) + [54, 55]\n",
    "X = data[:, X_slice]\n",
    "y = data[:, 53]\n",
    "\n",
    "# Fix the class labels by making them one-hot\n",
    "# Normally, I think this should be fit on the training data only, but if we know there are only seven different\n",
    "# covertypes, I don't see the problem in just doing fit_transform on y. Also prevents an exception if we see\n",
    "# a covertype in the test data that isn't in the train data, although, that would be pretty unlikely given the number of\n",
    "# points in the dataset.\n",
    "ohe = sklpp.OneHotEncoder()\n",
    "y_oh = ohe.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "y = np.asarray(y.ravel())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nu1JKxZj/Bxwm0nm8b5L6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First, to get a better idea for the data, let's do a PCA of two features and graph it.\n",
    "# First, use a standard scalar so that no one feature dominates the PCA.\n",
    "\n",
    "def color(cl):\n",
    "    if cl == 1:\n",
    "        return 'red'\n",
    "    elif cl == 2:\n",
    "        return 'orange'\n",
    "    elif cl == 3:\n",
    "        return 'yellow'\n",
    "    elif cl == 4:\n",
    "        return 'green'\n",
    "    elif cl == 5:\n",
    "        return 'blue'\n",
    "    elif cl == 6:\n",
    "        return 'purple'\n",
    "    elif cl == 7:\n",
    "        return 'gray'\n",
    "    else:\n",
    "        print('Unknown class', cl)\n",
    "        exit(1)\n",
    "\n",
    "ss = sklpp.StandardScaler()\n",
    "X_pca = ss.fit_transform(X)\n",
    "\n",
    "pca = skldecomp.PCA(n_components = 2)\n",
    "pca_points = pca.fit_transform(X_pca)\n",
    "\n",
    "colors = [color(y_cur) for y_cur in y]\n",
    "plt.scatter(pca_points[:, 0], pca_points[:, 1], c = colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As you can see, there's a wide degree of overlap between the seven covertypes in the first two elements of the PCA.\n",
    "# There is a clear pattern/cluster to the colors, though, but several of the colors overlap. It's also still possible\n",
    "# that the classes are linear in a higher dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def do_multi_label(classifier, classifier_name):\n",
    "    classifier_ovo = sklmc.OneVsOneClassifier(classifier)\n",
    "    classifier_ovo.fit(X_tr, y_tr)\n",
    "    print('\"' + classifier_name, 'OVO\",\"', str(classifier_ovo.score(X_te, y_te)) + '\"')\n",
    "    classifier_ovr = sklmc.OneVsRestClassifier(classifier)\n",
    "    classifier_ovr.fit(X_tr, y_tr)\n",
    "    print('\"' + classifier_name, 'OVR\",\"', str(classifier_ovr.score(X_te, y_te)) + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_list(base, start, end):\n",
    "    result = []\n",
    "    accum = base ** start\n",
    "    for cur in range(end - start):\n",
    "        result += [accum]\n",
    "        accum *= base\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"MLP (1, 16)\",\"0.7309941521698067\"\n",
      "\"MLP (1, 32)\",\"0.7313381492127903\"\n",
      "\"MLP (1, 64)\",\"0.7368421050376157\"\n",
      "\"MLP (1, 128)\",\"0.7426900586025552\"\n",
      "\"MLP (1, 256)\",\"0.7450980389901442\"\n",
      "\"MLP (2, 16)\",\"0.7285861714336526\"\n",
      "\"MLP (2, 32)\",\"0.7488820092104783\"\n",
      "\"MLP (2, 64)\",\"0.7671138632121183\"\n",
      "\"MLP (2, 128)\",\"0.8073615410256558\"\n",
      "\"MLP (2, 256)\",\"0.8145854835826833\"\n",
      "\"MLP (4, 16)\",\"0.7337461302975096\"\n",
      "\"MLP (4, 32)\",\"0.763673890383333\"\n",
      "\"MLP (4, 64)\",\"0.7942896459493843\"\n",
      "\"MLP (4, 128)\",\"0.8118335055164918\"\n",
      "\"MLP (4, 256)\",\"0.834537323619395\"\n",
      "\"MLP (8, 16)\",\"0.7358101134370765\"\n",
      "\"MLP (8, 32)\",\"0.7368421051811426\"\n",
      "\"MLP (8, 64)\",\"0.7997936015691715\"\n",
      "\"MLP (8, 128)\",\"0.8025455797583859\"\n",
      "\"MLP (8, 256)\",\"0.8135534913465252\"\n",
      "\"Naive Bayes OVO\",\" 0.09459924320605435\"\n",
      "\"Naive Bayes OVR\",\" 0.13140694874441006\"\n",
      "\"Decision Tree (gini, best, 2) OVO\",\" 0.6831785345717234\"\n",
      "\"Decision Tree (gini, best, 2) OVR\",\" 0.6773305813553492\"\n",
      "\"Decision Tree (gini, best, 4) OVO\",\" 0.7210182318541452\"\n",
      "\"Decision Tree (gini, best, 4) OVR\",\" 0.7265221878224974\"\n",
      "\"Decision Tree (gini, best, 8) OVO\",\" 0.7516339869281046\"\n",
      "\"Decision Tree (gini, best, 8) OVR\",\" 0.7616099071207431\"\n",
      "\"Decision Tree (gini, best, 16) OVO\",\" 0.7746818025455796\"\n",
      "\"Decision Tree (gini, best, 16) OVR\",\" 0.7671138630890952\"\n",
      "\"Decision Tree (gini, best, 32) OVO\",\" 0.7674578603371173\"\n",
      "\"Decision Tree (gini, best, 32) OVR\",\" 0.7189542483660131\"\n",
      "\"Decision Tree (gini, best, 64) OVO\",\" 0.7712418300653595\"\n",
      "\"Decision Tree (gini, best, 64) OVR\",\" 0.7244582043343654\"\n",
      "\"Decision Tree (gini, random, 2) OVO\",\" 0.5930512555899553\"\n",
      "\"Decision Tree (gini, random, 2) OVR\",\" 0.6394908840729274\"\n",
      "\"Decision Tree (gini, random, 4) OVO\",\" 0.6394908840729274\"\n",
      "\"Decision Tree (gini, random, 4) OVR\",\" 0.696938424492604\"\n",
      "\"Decision Tree (gini, random, 8) OVO\",\" 0.7437220502235982\"\n",
      "\"Decision Tree (gini, random, 8) OVR\",\" 0.7337461300309598\"\n",
      "\"Decision Tree (gini, random, 16) OVO\",\" 0.7750257997936016\"\n",
      "\"Decision Tree (gini, random, 16) OVR\",\" 0.7708978328173375\"\n",
      "\"Decision Tree (gini, random, 32) OVO\",\" 0.7739938080495357\"\n",
      "\"Decision Tree (gini, random, 32) OVR\",\" 0.7299621603027175\"\n",
      "\"Decision Tree (gini, random, 64) OVO\",\" 0.7695218438252494\"\n",
      "\"Decision Tree (gini, random, 64) OVR\",\" 0.7223942208462333\"\n",
      "\"Decision Tree (entropy, best, 2) OVO\",\" 0.6714826281389749\"\n",
      "\"Decision Tree (entropy, best, 2) OVR\",\" 0.6797385620915033\"\n",
      "\"Decision Tree (entropy, best, 4) OVO\",\" 0.7076023391812866\"\n",
      "\"Decision Tree (entropy, best, 4) OVR\",\" 0.6993464052287581\"\n",
      "\"Decision Tree (entropy, best, 8) OVO\",\" 0.7471620227038184\"\n",
      "\"Decision Tree (entropy, best, 8) OVR\",\" 0.7547299621603027\"\n",
      "\"Decision Tree (entropy, best, 16) OVO\",\" 0.7767457860337117\"\n",
      "\"Decision Tree (entropy, best, 16) OVR\",\" 0.7726178190574475\"\n",
      "\"Decision Tree (entropy, best, 32) OVO\",\" 0.7764017887856897\"\n",
      "\"Decision Tree (entropy, best, 32) OVR\",\" 0.7457860337117304\"\n",
      "\"Decision Tree (entropy, best, 64) OVO\",\" 0.7794977640178878\"\n",
      "\"Decision Tree (entropy, best, 64) OVR\",\" 0.7334021327829378\"\n",
      "\"Decision Tree (entropy, random, 2) OVO\",\" 0.6783625730994152\"\n",
      "\"Decision Tree (entropy, random, 2) OVR\",\" 0.6384588923288613\"\n",
      "\"Decision Tree (entropy, random, 4) OVO\",\" 0.6147230822153423\"\n",
      "\"Decision Tree (entropy, random, 4) OVR\",\" 0.6381148950808394\"\n",
      "\"Decision Tree (entropy, random, 8) OVO\",\" 0.7192982456140351\"\n",
      "\"Decision Tree (entropy, random, 8) OVR\",\" 0.7137942896456828\"\n",
      "\"Decision Tree (entropy, random, 16) OVO\",\" 0.7791537667698658\"\n",
      "\"Decision Tree (entropy, random, 16) OVR\",\" 0.783625730994152\"\n",
      "\"Decision Tree (entropy, random, 32) OVO\",\" 0.7729618163054696\"\n",
      "\"Decision Tree (entropy, random, 32) OVR\",\" 0.7285861713106295\"\n",
      "\"Decision Tree (entropy, random, 64) OVO\",\" 0.7843137254901961\"\n",
      "\"Decision Tree (entropy, random, 64) OVR\",\" 0.716890264877881\"\n",
      "\"SVM OVR (linear)\",\"0.7254901960784313\"\n",
      "\"SVM OVR (poly)\",\"0.7272101823185414\"\n",
      "\"SVM OVR (rbf)\",\"0.741314069487444\"\n",
      "\"SVM OVR (sigmoid)\",\"0.6243550051599587\"\n",
      "\"Logistic Regression (l2) OVO\",\" 0.7148262813897489\"\n",
      "\"Logistic Regression (l2) OVR\",\" 0.7096663226694186\"\n",
      "\"Logistic Regression (l1) OVO\",\" 0.7162022703818369\"\n",
      "\"Logistic Regression (l1) OVR\",\" 0.7089783281733746\"\n",
      "\"MLP (1, 16)\",\"0.71792225674497\"\n",
      "\"MLP (1, 32)\",\"0.7285861712901257\"\n",
      "\"MLP (1, 64)\",\"0.7354661160455277\"\n",
      "\"MLP (1, 128)\",\"0.7437220503466212\"\n",
      "\"MLP (1, 256)\",\"0.7485380119624563\"\n",
      "\"MLP (2, 16)\",\"0.7230822154653003\"\n",
      "\"MLP (2, 32)\",\"0.7258341932444381\"\n",
      "\"MLP (2, 64)\",\"0.7774337807963057\"\n",
      "\"MLP (2, 128)\",\"0.7970416237285222\"\n",
      "\"MLP (2, 256)\",\"0.8163054697612819\"\n",
      "\"MLP (4, 16)\",\"0.7196422427800417\"\n",
      "\"MLP (4, 32)\",\"0.7574819404110287\"\n",
      "\"MLP (4, 64)\",\"0.8022015825923793\"\n",
      "\"MLP (4, 128)\",\"0.8280013762555419\"\n",
      "\"MLP (4, 256)\",\"0.8441692469125767\"\n",
      "\"MLP (8, 16)\",\"0.7230822153217734\"\n",
      "\"MLP (8, 32)\",\"0.7595459238991608\"\n",
      "\"MLP (8, 64)\",\"0.7801857584319165\"\n",
      "\"MLP (8, 128)\",\"0.8194014448499531\"\n",
      "\"MLP (8, 256)\",\"0.8249054006132671\"\n",
      "\"Naive Bayes OVO\",\" 0.09184726522187822\"\n",
      "\"Naive Bayes OVR\",\" 0.12315101479188166\"\n",
      "\"Decision Tree (gini, best, 2) OVO\",\" 0.6721706226350189\"\n",
      "\"Decision Tree (gini, best, 2) OVR\",\" 0.6670106639146887\"\n",
      "\"Decision Tree (gini, best, 4) OVO\",\" 0.6976264189886481\"\n",
      "\"Decision Tree (gini, best, 4) OVR\",\" 0.7045063639490884\"\n",
      "\"Decision Tree (gini, best, 8) OVO\",\" 0.7567939456484348\"\n",
      "\"Decision Tree (gini, best, 8) OVR\",\" 0.7485380116959064\"\n",
      "\"Decision Tree (gini, best, 16) OVO\",\" 0.7739938080495357\"\n",
      "\"Decision Tree (gini, best, 16) OVR\",\" 0.762297901616787\"\n",
      "\"Decision Tree (gini, best, 32) OVO\",\" 0.7650498796009632\"\n",
      "\"Decision Tree (gini, best, 32) OVR\",\" 0.718610251117991\"\n",
      "\"Decision Tree (gini, best, 64) OVO\",\" 0.7681458548331613\"\n",
      "\"Decision Tree (gini, best, 64) OVR\",\" 0.7127622979016168\"\n",
      "\"Decision Tree (gini, random, 2) OVO\",\" 0.5958032335741315\"\n",
      "\"Decision Tree (gini, random, 2) OVR\",\" 0.6573787409700722\"\n",
      "\"Decision Tree (gini, random, 4) OVO\",\" 0.6714826281389749\"\n",
      "\"Decision Tree (gini, random, 4) OVR\",\" 0.6873065015479877\"\n",
      "\"Decision Tree (gini, random, 8) OVO\",\" 0.7258341933264534\"\n",
      "\"Decision Tree (gini, random, 8) OVR\",\" 0.7272101823185414\"\n",
      "\"Decision Tree (gini, random, 16) OVO\",\" 0.7722738218094255\"\n",
      "\"Decision Tree (gini, random, 16) OVR\",\" 0.7798417612659099\"\n",
      "\"Decision Tree (gini, random, 32) OVO\",\" 0.7708978328173375\"\n",
      "\"Decision Tree (gini, random, 32) OVR\",\" 0.7227382180942552\"\n",
      "\"Decision Tree (gini, random, 64) OVO\",\" 0.7753697970416237\"\n",
      "\"Decision Tree (gini, random, 64) OVR\",\" 0.7148262813897489\"\n",
      "\"Decision Tree (entropy, best, 2) OVO\",\" 0.6639146886824906\"\n",
      "\"Decision Tree (entropy, best, 2) OVR\",\" 0.6670106639146887\"\n",
      "\"Decision Tree (entropy, best, 4) OVO\",\" 0.6986584107327142\"\n",
      "\"Decision Tree (entropy, best, 4) OVR\",\" 0.6934984520123839\"\n",
      "\"Decision Tree (entropy, best, 8) OVO\",\" 0.7433780529755762\"\n",
      "\"Decision Tree (entropy, best, 8) OVR\",\" 0.7509459924320605\"\n",
      "\"Decision Tree (entropy, best, 16) OVO\",\" 0.7815617475060199\"\n",
      "\"Decision Tree (entropy, best, 16) OVR\",\" 0.7784657722738219\"\n",
      "\"Decision Tree (entropy, best, 32) OVO\",\" 0.7880976952184382\"\n",
      "\"Decision Tree (entropy, best, 32) OVR\",\" 0.7316821465428277\"\n",
      "\"Decision Tree (entropy, best, 64) OVO\",\" 0.7863777089783281\"\n",
      "\"Decision Tree (entropy, best, 64) OVR\",\" 0.7340901272789818\"\n",
      "\"Decision Tree (entropy, random, 2) OVO\",\" 0.5325077399380805\"\n",
      "\"Decision Tree (entropy, random, 2) OVR\",\" 0.585827313381493\"\n",
      "\"Decision Tree (entropy, random, 4) OVO\",\" 0.6904024767801857\"\n",
      "\"Decision Tree (entropy, random, 4) OVR\",\" 0.6828345373237014\"\n",
      "\"Decision Tree (entropy, random, 8) OVO\",\" 0.718610251117991\"\n",
      "\"Decision Tree (entropy, random, 8) OVR\",\" 0.7076023391812866\"\n",
      "\"Decision Tree (entropy, random, 16) OVO\",\" 0.7526659786721707\"\n",
      "\"Decision Tree (entropy, random, 16) OVR\",\" 0.7750257997936016\"\n",
      "\"Decision Tree (entropy, random, 32) OVO\",\" 0.781905744754042\"\n",
      "\"Decision Tree (entropy, random, 32) OVR\",\" 0.7330581355349157\"\n",
      "\"Decision Tree (entropy, random, 64) OVO\",\" 0.7918816649466804\"\n",
      "\"Decision Tree (entropy, random, 64) OVR\",\" 0.7127622979016168\"\n",
      "\"SVM OVR (linear)\",\"0.7096663226694186\"\n",
      "\"SVM OVR (poly)\",\"0.7268661850705195\"\n",
      "\"SVM OVR (rbf)\",\"0.7299621603027175\"\n",
      "\"SVM OVR (sigmoid)\",\"0.5951152390780874\"\n",
      "\"Logistic Regression (l2) OVO\",\" 0.7124183006535948\"\n",
      "\"Logistic Regression (l2) OVR\",\" 0.7017543859649122\"\n",
      "\"Logistic Regression (l1) OVO\",\" 0.7127622979016168\"\n",
      "\"Logistic Regression (l1) OVR\",\" 0.7014103887168902\"\n",
      "\"MLP (1, 16)\",\"0.749483826401639\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"MLP (1, 32)\",\"0.7591190641285712\"\n",
      "\"MLP (1, 64)\",\"0.7615278734885161\"\n",
      "\"MLP (1, 128)\",\"0.7749483824924855\"\n",
      "\"MLP (1, 256)\",\"0.7732278046653915\"\n",
      "\"MLP (2, 16)\",\"0.7584308328418509\"\n",
      "\"MLP (2, 32)\",\"0.7677219544126507\"\n",
      "\"MLP (2, 64)\",\"0.794907088904896\"\n",
      "\"MLP (2, 128)\",\"0.8052305573442436\"\n",
      "\"MLP (2, 256)\",\"0.8327598071721859\"\n",
      "\"MLP (4, 16)\",\"0.7529249828762624\"\n",
      "\"MLP (4, 32)\",\"0.7622161044470622\"\n",
      "\"MLP (4, 64)\",\"0.8100481763102643\"\n",
      "\"MLP (4, 128)\",\"0.8434273917266442\"\n",
      "\"MLP (4, 256)\",\"0.8489332416922326\"\n",
      "\"MLP (8, 16)\",\"0.7474191326235216\"\n",
      "\"MLP (8, 32)\",\"0.7642807984302886\"\n",
      "\"MLP (8, 64)\",\"0.8245010324699339\"\n",
      "\"MLP (8, 128)\",\"0.8117687544245106\"\n",
      "\"MLP (8, 256)\",\"0.8279421884112742\"\n",
      "\"Naive Bayes OVO\",\" 0.09669649002064694\"\n",
      "\"Naive Bayes OVR\",\" 0.13110805230557468\"\n",
      "\"Decision Tree (gini, best, 2) OVO\",\" 0.6878871300757055\"\n",
      "\"Decision Tree (gini, best, 2) OVR\",\" 0.6724019270474879\"\n",
      "\"Decision Tree (gini, best, 4) OVO\",\" 0.7192016517549896\"\n",
      "\"Decision Tree (gini, best, 4) OVR\",\" 0.7271163110805231\"\n",
      "\"Decision Tree (gini, best, 8) OVO\",\" 0.7684101858224364\"\n",
      "\"Decision Tree (gini, best, 8) OVR\",\" 0.7821748107364074\"\n",
      "\"Decision Tree (gini, best, 16) OVO\",\" 0.7807983482450104\"\n",
      "\"Decision Tree (gini, best, 16) OVR\",\" 0.7794218857536133\"\n",
      "\"Decision Tree (gini, best, 32) OVO\",\" 0.7725395732966277\"\n",
      "\"Decision Tree (gini, best, 32) OVR\",\" 0.7305574673090158\"\n",
      "\"Decision Tree (gini, best, 64) OVO\",\" 0.7725395732966277\"\n",
      "\"Decision Tree (gini, best, 64) OVR\",\" 0.7274604267033723\"\n",
      "\"Decision Tree (gini, random, 2) OVO\",\" 0.6569167240192705\"\n",
      "\"Decision Tree (gini, random, 2) OVR\",\" 0.6469373709566414\"\n",
      "\"Decision Tree (gini, random, 4) OVO\",\" 0.6025464556090847\"\n",
      "\"Decision Tree (gini, random, 4) OVR\",\" 0.6348933241569167\"\n",
      "\"Decision Tree (gini, random, 8) OVO\",\" 0.7081899518238128\"\n",
      "\"Decision Tree (gini, random, 8) OVR\",\" 0.7570543702684102\"\n",
      "\"Decision Tree (gini, random, 16) OVO\",\" 0.7935306262904336\"\n",
      "\"Decision Tree (gini, random, 16) OVR\",\" 0.7856159669649002\"\n",
      "\"Decision Tree (gini, random, 32) OVO\",\" 0.7801101169993118\"\n",
      "\"Decision Tree (gini, random, 32) OVR\",\" 0.7195457673778389\"\n",
      "\"Decision Tree (gini, random, 64) OVO\",\" 0.7752924982794219\"\n",
      "\"Decision Tree (gini, random, 64) OVR\",\" 0.725739848589126\"\n",
      "\"Decision Tree (entropy, best, 2) OVO\",\" 0.673778389538885\"\n",
      "\"Decision Tree (entropy, best, 2) OVR\",\" 0.6593255333792154\"\n",
      "\"Decision Tree (entropy, best, 4) OVO\",\" 0.7136958017894013\"\n",
      "\"Decision Tree (entropy, best, 4) OVR\",\" 0.6937370956641431\"\n",
      "\"Decision Tree (entropy, best, 8) OVO\",\" 0.7635925671025464\"\n",
      "\"Decision Tree (entropy, best, 8) OVR\",\" 0.7632484514796972\"\n",
      "\"Decision Tree (entropy, best, 16) OVO\",\" 0.7986923606331727\"\n",
      "\"Decision Tree (entropy, best, 16) OVR\",\" 0.7849277357192016\"\n",
      "\"Decision Tree (entropy, best, 32) OVO\",\" 0.8000688231245698\"\n",
      "\"Decision Tree (entropy, best, 32) OVR\",\" 0.7432897453544391\"\n",
      "\"Decision Tree (entropy, best, 64) OVO\",\" 0.7976600137646249\"\n",
      "\"Decision Tree (entropy, best, 64) OVR\",\" 0.7329662766689607\"\n",
      "\"Decision Tree (entropy, random, 2) OVO\",\" 0.5739848589125947\"\n",
      "\"Decision Tree (entropy, random, 2) OVR\",\" 0.5609084652443221\"\n",
      "\"Decision Tree (entropy, random, 4) OVO\",\" 0.6679284239504474\"\n",
      "\"Decision Tree (entropy, random, 4) OVR\",\" 0.6937370956641431\"\n",
      "\"Decision Tree (entropy, random, 8) OVO\",\" 0.7178251892635926\"\n",
      "\"Decision Tree (entropy, random, 8) OVR\",\" 0.7467309015829319\"\n",
      "\"Decision Tree (entropy, random, 16) OVO\",\" 0.7807983482450104\"\n",
      "\"Decision Tree (entropy, random, 16) OVR\",\" 0.7845836200963524\"\n",
      "\"Decision Tree (entropy, random, 32) OVO\",\" 0.7859600825877495\"\n",
      "\"Decision Tree (entropy, random, 32) OVR\",\" 0.7501720578114246\"\n",
      "\"Decision Tree (entropy, random, 64) OVO\",\" 0.7797660013764625\"\n",
      "\"Decision Tree (entropy, random, 64) OVR\",\" 0.7229869236063318\"\n",
      "\"SVM OVR (linear)\",\"0.7346868547832072\"\n",
      "\"SVM OVR (poly)\",\"0.751892635925671\"\n",
      "\"SVM OVR (rbf)\",\"0.760495526496903\"\n",
      "\"SVM OVR (sigmoid)\",\"0.609084652443221\"\n",
      "\"Logistic Regression (l2) OVO\",\" 0.7319339298004129\"\n",
      "\"Logistic Regression (l2) OVR\",\" 0.7164487267721955\"\n",
      "\"Logistic Regression (l1) OVO\",\" 0.73331039229181\"\n",
      "\"Logistic Regression (l1) OVR\",\" 0.7161046111493462\"\n",
      "\"MLP (1, 16)\",\"0.7291810048996623\"\n",
      "\"MLP (1, 32)\",\"0.7426015141907841\"\n",
      "\"MLP (1, 64)\",\"0.7556779078590566\"\n",
      "\"MLP (1, 128)\",\"0.7594631794232463\"\n",
      "\"MLP (1, 256)\",\"0.7611837575374926\"\n",
      "\"MLP (2, 16)\",\"0.7388162423804638\"\n",
      "\"MLP (2, 32)\",\"0.7577426015961523\"\n",
      "\"MLP (2, 64)\",\"0.7866483136693609\"\n",
      "\"MLP (2, 128)\",\"0.8079834825731685\"\n",
      "\"MLP (2, 256)\",\"0.8193392980861729\"\n",
      "\"MLP (4, 16)\",\"0.7422573986089566\"\n",
      "\"MLP (4, 32)\",\"0.7801101168352247\"\n",
      "\"MLP (4, 64)\",\"0.8035099794351062\"\n",
      "\"MLP (4, 128)\",\"0.8331039227540133\"\n",
      "\"MLP (4, 256)\",\"0.8458362010865891\"\n",
      "\"MLP (8, 16)\",\"0.7360633173976696\"\n",
      "\"MLP (8, 32)\",\"0.7577426015961523\"\n",
      "\"MLP (8, 64)\",\"0.8004129388704845\"\n",
      "\"MLP (8, 128)\",\"0.8041982106808048\"\n",
      "\"MLP (8, 256)\",\"0.8251892636746107\"\n",
      "\"Naive Bayes OVO\",\" 0.09050240880935995\"\n",
      "\"Naive Bayes OVR\",\" 0.12422573984858913\"\n",
      "\"Decision Tree (gini, best, 2) OVO\",\" 0.6913282863041982\"\n",
      "\"Decision Tree (gini, best, 2) OVR\",\" 0.686166551961459\"\n",
      "\"Decision Tree (gini, best, 4) OVO\",\" 0.7212663454920853\"\n",
      "\"Decision Tree (gini, best, 4) OVR\",\" 0.7312456985547143\"\n",
      "\"Decision Tree (gini, best, 8) OVO\",\" 0.7653131452167928\"\n",
      "\"Decision Tree (gini, best, 8) OVR\",\" 0.7649690295939435\"\n",
      "\"Decision Tree (gini, best, 16) OVO\",\" 0.7811424638678596\"\n",
      "\"Decision Tree (gini, best, 16) OVR\",\" 0.7739160357880248\"\n",
      "\"Decision Tree (gini, best, 32) OVO\",\" 0.7787336545079147\"\n",
      "\"Decision Tree (gini, best, 32) OVR\",\" 0.725739848589126\"\n",
      "\"Decision Tree (gini, best, 64) OVO\",\" 0.7763248451479697\"\n",
      "\"Decision Tree (gini, best, 64) OVR\",\" 0.725739848589126\"\n",
      "\"Decision Tree (gini, random, 2) OVO\",\" 0.6672401927047488\"\n",
      "\"Decision Tree (gini, random, 2) OVR\",\" 0.6383344803854095\"\n",
      "\"Decision Tree (gini, random, 4) OVO\",\" 0.6982105987611837\"\n",
      "\"Decision Tree (gini, random, 4) OVR\",\" 0.7054370268410186\"\n",
      "\"Decision Tree (gini, random, 8) OVO\",\" 0.7112869924294563\"\n",
      "\"Decision Tree (gini, random, 8) OVR\",\" 0.7350309704060565\"\n",
      "\"Decision Tree (gini, random, 16) OVO\",\" 0.7735719201651755\"\n",
      "\"Decision Tree (gini, random, 16) OVR\",\" 0.7746042670337233\"\n",
      "\"Decision Tree (gini, random, 32) OVO\",\" 0.7832071576049553\"\n",
      "\"Decision Tree (gini, random, 32) OVR\",\" 0.7319339298004129\"\n",
      "\"Decision Tree (gini, random, 64) OVO\",\" 0.7660013764624914\"\n",
      "\"Decision Tree (gini, random, 64) OVR\",\" 0.7174810736407433\"\n",
      "\"Decision Tree (entropy, best, 2) OVO\",\" 0.6789401238816243\"\n",
      "\"Decision Tree (entropy, best, 2) OVR\",\" 0.6847900894700619\"\n",
      "\"Decision Tree (entropy, best, 4) OVO\",\" 0.7112869924294563\"\n",
      "\"Decision Tree (entropy, best, 4) OVR\",\" 0.7099105299380591\"\n",
      "\"Decision Tree (entropy, best, 8) OVO\",\" 0.7549896765313145\"\n",
      "\"Decision Tree (entropy, best, 8) OVR\",\" 0.7629043358568479\"\n",
      "\"Decision Tree (entropy, best, 16) OVO\",\" 0.7825189263592567\"\n",
      "\"Decision Tree (entropy, best, 16) OVR\",\" 0.7894012388162422\"\n",
      "\"Decision Tree (entropy, best, 32) OVO\",\" 0.7807983482450104\"\n",
      "\"Decision Tree (entropy, best, 32) OVR\",\" 0.7346868547832072\"\n",
      "\"Decision Tree (entropy, best, 64) OVO\",\" 0.7773571920165175\"\n",
      "\"Decision Tree (entropy, best, 64) OVR\",\" 0.7305574673090158\"\n",
      "\"Decision Tree (entropy, random, 2) OVO\",\" 0.6056434962147281\"\n",
      "\"Decision Tree (entropy, random, 2) OVR\",\" 0.6768754301445286\"\n",
      "\"Decision Tree (entropy, random, 4) OVO\",\" 0.7013076393668273\"\n",
      "\"Decision Tree (entropy, random, 4) OVR\",\" 0.6868547832071576\"\n",
      "\"Decision Tree (entropy, random, 8) OVO\",\" 0.7319339298004129\"\n",
      "\"Decision Tree (entropy, random, 8) OVR\",\" 0.7309015829318651\"\n",
      "\"Decision Tree (entropy, random, 16) OVO\",\" 0.7787336545079147\"\n",
      "\"Decision Tree (entropy, random, 16) OVR\",\" 0.764280798348245\"\n",
      "\"Decision Tree (entropy, random, 32) OVO\",\" 0.7690984170681349\"\n",
      "\"Decision Tree (entropy, random, 32) OVR\",\" 0.7188575361321404\"\n",
      "\"Decision Tree (entropy, random, 64) OVO\",\" 0.7804542326221611\"\n",
      "\"Decision Tree (entropy, random, 64) OVR\",\" 0.7202339986235375\"\n",
      "\"SVM OVR (linear)\",\"0.7305574673090158\"\n",
      "\"SVM OVR (poly)\",\"0.7353750860289057\"\n",
      "\"SVM OVR (rbf)\",\"0.7477632484514797\"\n",
      "\"SVM OVR (sigmoid)\",\"0.6266345492085341\"\n",
      "\"Logistic Regression (l2) OVO\",\" 0.7374397797660014\"\n",
      "\"Logistic Regression (l2) OVR\",\" 0.7226428079834825\"\n",
      "\"Logistic Regression (l1) OVO\",\" 0.7374397797660014\"\n",
      "\"Logistic Regression (l1) OVR\",\" 0.7250516173434274\"\n",
      "\"MLP (1, 16)\",\"0.7319339300055219\"\n",
      "\"MLP (1, 32)\",\"0.7460426702551898\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"MLP (1, 64)\",\"0.7584308326777638\"\n",
      "\"MLP (1, 128)\",\"0.7632484516437843\"\n",
      "\"MLP (1, 256)\",\"0.7697866481497463\"\n",
      "\"MLP (2, 16)\",\"0.7487955954841147\"\n",
      "\"MLP (2, 32)\",\"0.7629043359799133\"\n",
      "\"MLP (2, 64)\",\"0.7842395045555467\"\n",
      "\"MLP (2, 128)\",\"0.8038540950169337\"\n",
      "\"MLP (2, 256)\",\"0.8231245696503625\"\n",
      "\"MLP (4, 16)\",\"0.7460426705013204\"\n",
      "\"MLP (4, 32)\",\"0.7752924981153347\"\n",
      "\"MLP (4, 64)\",\"0.8011011700751612\"\n",
      "\"MLP (4, 128)\",\"0.8337921539586901\"\n",
      "\"MLP (4, 256)\",\"0.8375774260561629\"\n",
      "\"MLP (8, 16)\",\"0.7374397796839578\"\n",
      "\"MLP (8, 32)\",\"0.7611837575785144\"\n",
      "\"MLP (8, 64)\",\"0.7955953198634421\"\n",
      "\"MLP (8, 128)\",\"0.8310392292220266\"\n",
      "\"MLP (8, 256)\",\"0.829318651148802\"\n",
      "\"Naive Bayes OVO\",\" 0.14039917412250516\"\n",
      "\"Naive Bayes OVR\",\" 0.1276668960770819\"\n",
      "\"Decision Tree (gini, best, 2) OVO\",\" 0.692360633172746\"\n",
      "\"Decision Tree (gini, best, 2) OVR\",\" 0.6830695113558155\"\n",
      "\"Decision Tree (gini, best, 4) OVO\",\" 0.7305574673090158\"\n",
      "\"Decision Tree (gini, best, 4) OVR\",\" 0.7302133516861665\"\n",
      "\"Decision Tree (gini, best, 8) OVO\",\" 0.7794218857536133\"\n",
      "\"Decision Tree (gini, best, 8) OVR\",\" 0.7697866483138335\"\n",
      "\"Decision Tree (gini, best, 16) OVO\",\" 0.7807983482450104\"\n",
      "\"Decision Tree (gini, best, 16) OVR\",\" 0.7694425326909842\"\n",
      "\"Decision Tree (gini, best, 32) OVO\",\" 0.7783895388850653\"\n",
      "\"Decision Tree (gini, best, 32) OVR\",\" 0.7346868547832072\"\n",
      "\"Decision Tree (gini, best, 64) OVO\",\" 0.7880247763248451\"\n",
      "\"Decision Tree (gini, best, 64) OVR\",\" 0.7319339298004129\"\n",
      "\"Decision Tree (gini, random, 2) OVO\",\" 0.5801789401238816\"\n",
      "\"Decision Tree (gini, random, 2) OVR\",\" 0.6025464556090847\"\n",
      "\"Decision Tree (gini, random, 4) OVO\",\" 0.6607019958706125\"\n",
      "\"Decision Tree (gini, random, 4) OVR\",\" 0.7130075705437027\"\n",
      "\"Decision Tree (gini, random, 8) OVO\",\" 0.7432897453544391\"\n",
      "\"Decision Tree (gini, random, 8) OVR\",\" 0.735719201651755\"\n",
      "\"Decision Tree (gini, random, 16) OVO\",\" 0.7973158981417756\"\n",
      "\"Decision Tree (gini, random, 16) OVR\",\" 0.7673778389538886\"\n",
      "\"Decision Tree (gini, random, 32) OVO\",\" 0.7832071576049553\"\n",
      "\"Decision Tree (gini, random, 32) OVR\",\" 0.7312456985547143\"\n",
      "\"Decision Tree (gini, random, 64) OVO\",\" 0.7949070887818307\"\n",
      "\"Decision Tree (gini, random, 64) OVR\",\" 0.7271163110805231\"\n",
      "\"Decision Tree (entropy, best, 2) OVO\",\" 0.6806607019958706\"\n",
      "\"Decision Tree (entropy, best, 2) OVR\",\" 0.6813489332415692\"\n",
      "\"Decision Tree (entropy, best, 4) OVO\",\" 0.7119752236751549\"\n",
      "\"Decision Tree (entropy, best, 4) OVR\",\" 0.6951135581555402\"\n",
      "\"Decision Tree (entropy, best, 8) OVO\",\" 0.7615278733654508\"\n",
      "\"Decision Tree (entropy, best, 8) OVR\",\" 0.7680660701995871\"\n",
      "\"Decision Tree (entropy, best, 16) OVO\",\" 0.7918100481761872\"\n",
      "\"Decision Tree (entropy, best, 16) OVR\",\" 0.7821748107364074\"\n",
      "\"Decision Tree (entropy, best, 32) OVO\",\" 0.7949070887818307\"\n",
      "\"Decision Tree (entropy, best, 32) OVR\",\" 0.7343427391603579\"\n",
      "\"Decision Tree (entropy, best, 64) OVO\",\" 0.7993805918788713\"\n",
      "\"Decision Tree (entropy, best, 64) OVR\",\" 0.7326221610461114\"\n",
      "\"Decision Tree (entropy, random, 2) OVO\",\" 0.6806607019958706\"\n",
      "\"Decision Tree (entropy, random, 2) OVR\",\" 0.6779077770130764\"\n",
      "\"Decision Tree (entropy, random, 4) OVO\",\" 0.6593255333792154\"\n",
      "\"Decision Tree (entropy, random, 4) OVR\",\" 0.6810048176187199\"\n",
      "\"Decision Tree (entropy, random, 8) OVO\",\" 0.7388162422573985\"\n",
      "\"Decision Tree (entropy, random, 8) OVR\",\" 0.7381280110116999\"\n",
      "\"Decision Tree (entropy, random, 16) OVO\",\" 0.7759807295251204\"\n",
      "\"Decision Tree (entropy, random, 16) OVR\",\" 0.7918100481761872\"\n",
      "\"Decision Tree (entropy, random, 32) OVO\",\" 0.7811424638678596\"\n",
      "\"Decision Tree (entropy, random, 32) OVR\",\" 0.7247075017205781\"\n",
      "\"Decision Tree (entropy, random, 64) OVO\",\" 0.7921541637990365\"\n",
      "\"Decision Tree (entropy, random, 64) OVR\",\" 0.7136958017894013\"\n",
      "\"SVM OVR (linear)\",\"0.7364074328974536\"\n",
      "\"SVM OVR (poly)\",\"0.7329662766689607\"\n",
      "\"SVM OVR (rbf)\",\"0.7573984858912595\"\n",
      "\"SVM OVR (sigmoid)\",\"0.635237439779766\"\n",
      "\"Logistic Regression (l2) OVO\",\" 0.735719201651755\"\n",
      "\"Logistic Regression (l2) OVR\",\" 0.723331039229181\"\n",
      "\"Logistic Regression (l1) OVO\",\" 0.7339986235375086\"\n",
      "\"Logistic Regression (l1) OVR\",\" 0.7243633860977289\"\n",
      "\"MLP (1, 16)\",\"0.7398485892900334\"\n",
      "\"MLP (1, 32)\",\"0.7429456298546552\"\n",
      "\"MLP (1, 64)\",\"0.7573984857681941\"\n",
      "\"MLP (1, 128)\",\"0.7632484516437843\"\n",
      "\"MLP (1, 256)\",\"0.7611837578656668\"\n",
      "\"MLP (2, 16)\",\"0.7346868546601418\"\n",
      "\"MLP (2, 32)\",\"0.7491397110659421\"\n",
      "\"MLP (2, 64)\",\"0.7838953886865667\"\n",
      "\"MLP (2, 128)\",\"0.7969717823138175\"\n",
      "\"MLP (2, 256)\",\"0.8179628355947758\"\n",
      "\"MLP (4, 16)\",\"0.7432897452313737\"\n",
      "\"MLP (4, 32)\",\"0.7677219546998031\"\n",
      "\"MLP (4, 64)\",\"0.7945629729948943\"\n",
      "\"MLP (4, 128)\",\"0.8310392292630484\"\n",
      "\"MLP (4, 256)\",\"0.8413626979485267\"\n",
      "\"MLP (8, 16)\",\"0.7322780453001969\"\n",
      "\"MLP (8, 32)\",\"0.7673778387898014\"\n",
      "\"MLP (8, 64)\",\"0.8110805232198338\"\n",
      "\"MLP (8, 128)\",\"0.8179628353486451\"\n",
      "\"MLP (8, 256)\",\"0.8255333790513293\"\n",
      "\"Naive Bayes OVO\",\" 0.0929112181693049\"\n",
      "\"Naive Bayes OVR\",\" 0.13145216792842396\"\n",
      "\"Decision Tree (gini, best, 2) OVO\",\" 0.6810048176187199\"\n",
      "\"Decision Tree (gini, best, 2) OVR\",\" 0.6734342739160358\"\n",
      "\"Decision Tree (gini, best, 4) OVO\",\" 0.7185134205092911\"\n",
      "\"Decision Tree (gini, best, 4) OVR\",\" 0.717136958017894\"\n",
      "\"Decision Tree (gini, best, 8) OVO\",\" 0.7625602202339986\"\n",
      "\"Decision Tree (gini, best, 8) OVR\",\" 0.7646249139710943\"\n",
      "\"Decision Tree (gini, best, 16) OVO\",\" 0.7873365450791466\"\n",
      "\"Decision Tree (gini, best, 16) OVR\",\" 0.7656572608396421\"\n",
      "\"Decision Tree (gini, best, 32) OVO\",\" 0.7721954576737784\"\n",
      "\"Decision Tree (gini, best, 32) OVR\",\" 0.7264280798348245\"\n",
      "\"Decision Tree (gini, best, 64) OVO\",\" 0.7787336545079147\"\n",
      "\"Decision Tree (gini, best, 64) OVR\",\" 0.725739848589126\"\n",
      "\"Decision Tree (gini, random, 2) OVO\",\" 0.6328286304198211\"\n",
      "\"Decision Tree (gini, random, 2) OVR\",\" 0.5877494838265658\"\n",
      "\"Decision Tree (gini, random, 4) OVO\",\" 0.6830695113558155\"\n",
      "\"Decision Tree (gini, random, 4) OVR\",\" 0.6999311768754302\"\n",
      "\"Decision Tree (gini, random, 8) OVO\",\" 0.7202339986235375\"\n",
      "\"Decision Tree (gini, random, 8) OVR\",\" 0.7284927735719202\"\n",
      "\"Decision Tree (gini, random, 16) OVO\",\" 0.7797660013764625\"\n",
      "\"Decision Tree (gini, random, 16) OVR\",\" 0.7746042670337233\"\n",
      "\"Decision Tree (gini, random, 32) OVO\",\" 0.7794218857536133\"\n",
      "\"Decision Tree (gini, random, 32) OVR\",\" 0.720922229869236\"\n",
      "\"Decision Tree (gini, random, 64) OVO\",\" 0.7690984170681349\"\n",
      "\"Decision Tree (gini, random, 64) OVR\",\" 0.7264280798348245\"\n",
      "\"Decision Tree (entropy, best, 2) OVO\",\" 0.6727460426703372\"\n",
      "\"Decision Tree (entropy, best, 2) OVR\",\" 0.6675843083275981\"\n",
      "\"Decision Tree (entropy, best, 4) OVO\",\" 0.7116311080523056\"\n",
      "\"Decision Tree (entropy, best, 4) OVR\",\" 0.6964900206469373\"\n",
      "\"Decision Tree (entropy, best, 8) OVO\",\" 0.7660013764624914\"\n",
      "\"Decision Tree (entropy, best, 8) OVR\",\" 0.7512044046799725\"\n",
      "\"Decision Tree (entropy, best, 16) OVO\",\" 0.7856159669649002\"\n",
      "\"Decision Tree (entropy, best, 16) OVR\",\" 0.7869924294562973\"\n",
      "\"Decision Tree (entropy, best, 32) OVO\",\" 0.7825189263592567\"\n",
      "\"Decision Tree (entropy, best, 32) OVR\",\" 0.7305574673090158\"\n",
      "\"Decision Tree (entropy, best, 64) OVO\",\" 0.7869924294562973\"\n",
      "\"Decision Tree (entropy, best, 64) OVR\",\" 0.7284927735719202\"\n",
      "\"Decision Tree (entropy, random, 2) OVO\",\" 0.6772195457673779\"\n",
      "\"Decision Tree (entropy, random, 2) OVR\",\" 0.6311080523055747\"\n",
      "\"Decision Tree (entropy, random, 4) OVO\",\" 0.5953200275292498\"\n",
      "\"Decision Tree (entropy, random, 4) OVR\",\" 0.6954576737783895\"\n",
      "\"Decision Tree (entropy, random, 8) OVO\",\" 0.7391603578802478\"\n",
      "\"Decision Tree (entropy, random, 8) OVR\",\" 0.7264280798348245\"\n",
      "\"Decision Tree (entropy, random, 16) OVO\",\" 0.7715072264280798\"\n",
      "\"Decision Tree (entropy, random, 16) OVR\",\" 0.7876806607019958\"\n",
      "\"Decision Tree (entropy, random, 32) OVO\",\" 0.7811424638678596\"\n",
      "\"Decision Tree (entropy, random, 32) OVR\",\" 0.7329662766689607\"\n",
      "\"Decision Tree (entropy, random, 64) OVO\",\" 0.7735719201651755\"\n",
      "\"Decision Tree (entropy, random, 64) OVR\",\" 0.7281486579490709\"\n",
      "\"SVM OVR (linear)\",\"0.7260839642119752\"\n",
      "\"SVM OVR (poly)\",\"0.7470750172057812\"\n",
      "\"SVM OVR (rbf)\",\"0.7501720578114246\"\n",
      "\"SVM OVR (sigmoid)\",\"0.6149346180316586\"\n",
      "\"Logistic Regression (l2) OVO\",\" 0.7123193392980042\"\n",
      "\"Logistic Regression (l2) OVR\",\" 0.7061252580867171\"\n",
      "\"Logistic Regression (l1) OVO\",\" 0.7126634549208534\"\n",
      "\"Logistic Regression (l1) OVR\",\" 0.7061252580867171\"\n",
      "\"MLP (1, 16)\",\"0.7341597796143251\"\n",
      "\"MLP (1, 32)\",\"0.737947658566404\"\n",
      "\"MLP (1, 64)\",\"0.755853994326158\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"MLP (1, 128)\",\"0.7534435260065988\"\n",
      "\"MLP (1, 256)\",\"0.7589531682082773\"\n",
      "\"MLP (2, 16)\",\"0.7441460055096418\"\n",
      "\"MLP (2, 32)\",\"0.7589531682082773\"\n",
      "\"MLP (2, 64)\",\"0.7727272728914728\"\n",
      "\"MLP (2, 128)\",\"0.809917355536101\"\n",
      "\"MLP (2, 256)\",\"0.8240358126721763\"\n",
      "\"MLP (4, 16)\",\"0.7499999998357999\"\n",
      "\"MLP (4, 32)\",\"0.7713498620947531\"\n",
      "\"MLP (4, 64)\",\"0.7954545452903453\"\n",
      "\"MLP (4, 128)\",\"0.8319559227008136\"\n",
      "\"MLP (4, 256)\",\"0.8333333331691332\"\n",
      "\"MLP (8, 16)\",\"0.744146005673842\"\n",
      "\"MLP (8, 32)\",\"0.7706611568605932\"\n",
      "\"MLP (8, 64)\",\"0.8112947656760202\"\n",
      "\"MLP (8, 128)\",\"0.8226584022038568\"\n",
      "\"MLP (8, 256)\",\"0.824724517742136\"\n",
      "\"Naive Bayes OVO\",\" 0.09710743801652892\"\n",
      "\"Naive Bayes OVR\",\" 0.12121212121212122\"\n",
      "\"Decision Tree (gini, best, 2) OVO\",\" 0.6900826446280992\"\n",
      "\"Decision Tree (gini, best, 2) OVR\",\" 0.6804407713498623\"\n",
      "\"Decision Tree (gini, best, 4) OVO\",\" 0.7272727272727273\"\n",
      "\"Decision Tree (gini, best, 4) OVR\",\" 0.7179752066115702\"\n",
      "\"Decision Tree (gini, best, 8) OVO\",\" 0.7558539944903582\"\n",
      "\"Decision Tree (gini, best, 8) OVR\",\" 0.7661845730027548\"\n",
      "\"Decision Tree (gini, best, 16) OVO\",\" 0.7668732782369146\"\n",
      "\"Decision Tree (gini, best, 16) OVR\",\" 0.7679063360881543\"\n",
      "\"Decision Tree (gini, best, 32) OVO\",\" 0.7572314049586777\"\n",
      "\"Decision Tree (gini, best, 32) OVR\",\" 0.7214187327823691\"\n",
      "\"Decision Tree (gini, best, 64) OVO\",\" 0.7630853994490359\"\n",
      "\"Decision Tree (gini, best, 64) OVR\",\" 0.7207300275482094\"\n",
      "\"Decision Tree (gini, random, 2) OVO\",\" 0.5767906336088154\"\n",
      "\"Decision Tree (gini, random, 2) OVR\",\" 0.5695592286501377\"\n",
      "\"Decision Tree (gini, random, 4) OVO\",\" 0.6294765840220385\"\n",
      "\"Decision Tree (gini, random, 4) OVR\",\" 0.6828512396694215\"\n",
      "\"Decision Tree (gini, random, 8) OVO\",\" 0.7379476584022039\"\n",
      "\"Decision Tree (gini, random, 8) OVR\",\" 0.7441460055096418\"\n",
      "\"Decision Tree (gini, random, 16) OVO\",\" 0.7916666666666666\"\n",
      "\"Decision Tree (gini, random, 16) OVR\",\" 0.759641873278237\"\n",
      "\"Decision Tree (gini, random, 32) OVO\",\" 0.7689393939393939\"\n",
      "\"Decision Tree (gini, random, 32) OVR\",\" 0.7200413223140496\"\n",
      "\"Decision Tree (gini, random, 64) OVO\",\" 0.7940771349862259\"\n",
      "\"Decision Tree (gini, random, 64) OVR\",\" 0.7238292011019284\"\n",
      "\"Decision Tree (entropy, best, 2) OVO\",\" 0.6797520661157025\"\n",
      "\"Decision Tree (entropy, best, 2) OVR\",\" 0.6773415977961432\"\n",
      "\"Decision Tree (entropy, best, 4) OVO\",\" 0.7193526170798898\"\n",
      "\"Decision Tree (entropy, best, 4) OVR\",\" 0.7000688705234159\"\n",
      "\"Decision Tree (entropy, best, 8) OVO\",\" 0.7510330578512396\"\n",
      "\"Decision Tree (entropy, best, 8) OVR\",\" 0.7513774104683195\"\n",
      "\"Decision Tree (entropy, best, 16) OVO\",\" 0.7765151515151515\"\n",
      "\"Decision Tree (entropy, best, 16) OVR\",\" 0.7727272727272727\"\n",
      "\"Decision Tree (entropy, best, 32) OVO\",\" 0.7854683195592287\"\n",
      "\"Decision Tree (entropy, best, 32) OVR\",\" 0.7448347107438017\"\n",
      "\"Decision Tree (entropy, best, 64) OVO\",\" 0.7851239669421488\"\n",
      "\"Decision Tree (entropy, best, 64) OVR\",\" 0.7417355371900827\"\n",
      "\"Decision Tree (entropy, random, 2) OVO\",\" 0.6342975206611571\"\n",
      "\"Decision Tree (entropy, random, 2) OVR\",\" 0.5829889807162535\"\n",
      "\"Decision Tree (entropy, random, 4) OVO\",\" 0.6759641873278237\"\n",
      "\"Decision Tree (entropy, random, 4) OVR\",\" 0.7103994490358126\"\n",
      "\"Decision Tree (entropy, random, 8) OVO\",\" 0.7255509641873278\"\n",
      "\"Decision Tree (entropy, random, 8) OVR\",\" 0.7331267217630854\"\n",
      "\"Decision Tree (entropy, random, 16) OVO\",\" 0.7768595041322314\"\n",
      "\"Decision Tree (entropy, random, 16) OVR\",\" 0.7692837465564738\"\n",
      "\"Decision Tree (entropy, random, 32) OVO\",\" 0.7847796143250688\"\n",
      "\"Decision Tree (entropy, random, 32) OVR\",\" 0.7310606060606061\"\n",
      "\"Decision Tree (entropy, random, 64) OVO\",\" 0.7933884297520661\"\n",
      "\"Decision Tree (entropy, random, 64) OVR\",\" 0.734504132231405\"\n",
      "\"SVM OVR (linear)\",\"0.7382920110192838\"\n",
      "\"SVM OVR (poly)\",\"0.7400137741046832\"\n",
      "\"SVM OVR (rbf)\",\"0.7527548209366391\"\n",
      "\"SVM OVR (sigmoid)\",\"0.6277548209366391\"\n",
      "\"Logistic Regression (l2) OVO\",\" 0.7341597796143251\"\n",
      "\"Logistic Regression (l2) OVR\",\" 0.71900826446281\"\n",
      "\"Logistic Regression (l1) OVO\",\" 0.7338154269972452\"\n",
      "\"Logistic Regression (l1) OVR\",\" 0.7200413223140496\"\n",
      "\"MLP (1, 16)\",\"0.743457300111282\"\n",
      "\"MLP (1, 32)\",\"0.7448347105796015\"\n",
      "\"MLP (1, 64)\",\"0.7586088152627971\"\n",
      "\"MLP (1, 128)\",\"0.756542699888718\"\n",
      "\"MLP (1, 256)\",\"0.7524104681553591\"\n",
      "\"MLP (2, 16)\",\"0.7424242422600423\"\n",
      "\"MLP (2, 32)\",\"0.7623966940506759\"\n",
      "\"MLP (2, 64)\",\"0.7792699722875905\"\n",
      "\"MLP (2, 128)\",\"0.7975206613212249\"\n",
      "\"MLP (2, 256)\",\"0.8068181816539817\"\n",
      "\"MLP (4, 16)\",\"0.7575757574115575\"\n",
      "\"MLP (4, 32)\",\"0.7813360879900698\"\n",
      "\"MLP (4, 64)\",\"0.805785123802742\"\n",
      "\"MLP (4, 128)\",\"0.8274793388429752\"\n",
      "\"MLP (4, 256)\",\"0.834710743965853\"\n",
      "\"MLP (8, 16)\",\"0.7551652890919982\"\n",
      "\"MLP (8, 32)\",\"0.7506887050699597\"\n",
      "\"MLP (8, 64)\",\"0.8068181816539817\"\n",
      "\"MLP (8, 128)\",\"0.830922864849574\"\n",
      "\"MLP (8, 256)\",\"0.8240358128363764\"\n",
      "\"Naive Bayes OVO\",\" 0.09745179063360881\"\n",
      "\"Naive Bayes OVR\",\" 0.12052341597796143\"\n",
      "\"Decision Tree (gini, best, 2) OVO\",\" 0.6942148760330579\"\n",
      "\"Decision Tree (gini, best, 2) OVR\",\" 0.6835399449035813\"\n",
      "\"Decision Tree (gini, best, 4) OVO\",\" 0.7272727272727273\"\n",
      "\"Decision Tree (gini, best, 4) OVR\",\" 0.7262396694214877\"\n",
      "\"Decision Tree (gini, best, 8) OVO\",\" 0.7682506887052342\"\n",
      "\"Decision Tree (gini, best, 8) OVR\",\" 0.7668732782369146\"\n",
      "\"Decision Tree (gini, best, 16) OVO\",\" 0.7823691460055097\"\n",
      "\"Decision Tree (gini, best, 16) OVR\",\" 0.7765151515151515\"\n",
      "\"Decision Tree (gini, best, 32) OVO\",\" 0.775137741046832\"\n",
      "\"Decision Tree (gini, best, 32) OVR\",\" 0.7258953168044077\"\n",
      "\"Decision Tree (gini, best, 64) OVO\",\" 0.7803030303030303\"\n",
      "\"Decision Tree (gini, best, 64) OVR\",\" 0.7289944903581267\"\n",
      "\"Decision Tree (gini, random, 2) OVO\",\" 0.5750688705234159\"\n",
      "\"Decision Tree (gini, random, 2) OVR\",\" 0.5895316804407713\"\n",
      "\"Decision Tree (gini, random, 4) OVO\",\" 0.6897382920110193\"\n",
      "\"Decision Tree (gini, random, 4) OVR\",\" 0.7024793388429752\"\n",
      "\"Decision Tree (gini, random, 8) OVO\",\" 0.731404958677686\"\n",
      "\"Decision Tree (gini, random, 8) OVR\",\" 0.7045454545454546\"\n",
      "\"Decision Tree (gini, random, 16) OVO\",\" 0.7899449035812672\"\n",
      "\"Decision Tree (gini, random, 16) OVR\",\" 0.7575757575757576\"\n",
      "\"Decision Tree (gini, random, 32) OVO\",\" 0.7816804407713499\"\n",
      "\"Decision Tree (gini, random, 32) OVR\",\" 0.7176308539944903\"\n",
      "\"Decision Tree (gini, random, 64) OVO\",\" 0.7727272727272727\"\n",
      "\"Decision Tree (gini, random, 64) OVR\",\" 0.7079889807162535\"\n",
      "\"Decision Tree (entropy, best, 2) OVO\",\" 0.6766528925619835\"\n",
      "\"Decision Tree (entropy, best, 2) OVR\",\" 0.6694214876033058\"\n",
      "\"Decision Tree (entropy, best, 4) OVO\",\" 0.721763085399449\"\n",
      "\"Decision Tree (entropy, best, 4) OVR\",\" 0.6980027548209367\"\n",
      "\"Decision Tree (entropy, best, 8) OVO\",\" 0.7606749311294766\"\n",
      "\"Decision Tree (entropy, best, 8) OVR\",\" 0.7599862258953168\"\n",
      "\"Decision Tree (entropy, best, 16) OVO\",\" 0.7741046831955923\"\n",
      "\"Decision Tree (entropy, best, 16) OVR\",\" 0.7689393939393939\"\n",
      "\"Decision Tree (entropy, best, 32) OVO\",\" 0.7772038567493113\"\n",
      "\"Decision Tree (entropy, best, 32) OVR\",\" 0.71900826446281\"\n",
      "\"Decision Tree (entropy, best, 64) OVO\",\" 0.7785812672176309\"\n",
      "\"Decision Tree (entropy, best, 64) OVR\",\" 0.721763085399449\"\n",
      "\"Decision Tree (entropy, random, 2) OVO\",\" 0.5840220385674931\"\n",
      "\"Decision Tree (entropy, random, 2) OVR\",\" 0.556129476584022\"\n",
      "\"Decision Tree (entropy, random, 4) OVO\",\" 0.6081267217630854\"\n",
      "\"Decision Tree (entropy, random, 4) OVR\",\" 0.637396694214876\"\n",
      "\"Decision Tree (entropy, random, 8) OVO\",\" 0.724862258953168\"\n",
      "\"Decision Tree (entropy, random, 8) OVR\",\" 0.7407024793388429\"\n",
      "\"Decision Tree (entropy, random, 16) OVO\",\" 0.772038567493113\"\n",
      "\"Decision Tree (entropy, random, 16) OVR\",\" 0.7827134986225895\"\n",
      "\"Decision Tree (entropy, random, 32) OVO\",\" 0.7706611570247934\"\n",
      "\"Decision Tree (entropy, random, 32) OVR\",\" 0.71866391184573\"\n",
      "\"Decision Tree (entropy, random, 64) OVO\",\" 0.7692837465564738\"\n",
      "\"Decision Tree (entropy, random, 64) OVR\",\" 0.7252066115702479\"\n",
      "\"SVM OVR (linear)\",\"0.7300275482093664\"\n",
      "\"SVM OVR (poly)\",\"0.7286501377410468\"\n",
      "\"SVM OVR (rbf)\",\"0.7493112947658402\"\n",
      "\"SVM OVR (sigmoid)\",\"0.637396694214876\"\n",
      "\"Logistic Regression (l2) OVO\",\" 0.7258953168044077\"\n",
      "\"Logistic Regression (l2) OVR\",\" 0.7183195592286501\"\n",
      "\"Logistic Regression (l1) OVO\",\" 0.7286501377410468\"\n",
      "\"Logistic Regression (l1) OVR\",\" 0.7179752066115702\"\n",
      "\"MLP (1, 16)\",\"0.7361350326631713\"\n",
      "\"MLP (1, 32)\",\"0.7468136410815035\"\n",
      "\"MLP (1, 64)\",\"0.7516362383946279\"\n",
      "\"MLP (1, 128)\",\"0.7605924906297015\"\n",
      "\"MLP (1, 256)\",\"0.7654150878606975\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"MLP (2, 16)\",\"0.736479503899823\"\n",
      "\"MLP (2, 32)\",\"0.7540475368869334\"\n",
      "\"MLP (2, 64)\",\"0.7867723042867203\"\n",
      "\"MLP (2, 128)\",\"0.7888391318708874\"\n",
      "\"MLP (2, 256)\",\"0.8129521182722524\"\n",
      "\"MLP (4, 16)\",\"0.7499138822113691\"\n",
      "\"MLP (4, 32)\",\"0.7599035478278846\"\n",
      "\"MLP (4, 64)\",\"0.7891836031075391\"\n",
      "\"MLP (4, 128)\",\"0.8277643814482772\"\n",
      "\"MLP (4, 256)\",\"0.8411987597598235\"\n",
      "\"MLP (8, 16)\",\"0.750602824766801\"\n",
      "\"MLP (8, 32)\",\"0.767826386599388\"\n",
      "\"MLP (8, 64)\",\"0.796761970231749\"\n",
      "\"MLP (8, 128)\",\"0.8046848085926107\"\n",
      "\"MLP (8, 256)\",\"0.8274199105196068\"\n",
      "\"Naive Bayes OVO\",\" 0.09438511884257665\"\n",
      "\"Naive Bayes OVR\",\" 0.12332070272132277\"\n",
      "\"Decision Tree (gini, best, 2) OVO\",\" 0.68515328970031\"\n",
      "\"Decision Tree (gini, best, 2) OVR\",\" 0.6789528074405787\"\n",
      "\"Decision Tree (gini, best, 4) OVO\",\" 0.7185669996555287\"\n",
      "\"Decision Tree (gini, best, 4) OVR\",\" 0.7175335859455736\"\n",
      "\"Decision Tree (gini, best, 8) OVO\",\" 0.7623148467102997\"\n",
      "\"Decision Tree (gini, best, 8) OVR\",\" 0.7623148467102997\"\n",
      "\"Decision Tree (gini, best, 16) OVO\",\" 0.7733379262831553\"\n",
      "\"Decision Tree (gini, best, 16) OVR\",\" 0.7771271098863245\"\n",
      "\"Decision Tree (gini, best, 32) OVO\",\" 0.7747158112297623\"\n",
      "\"Decision Tree (gini, best, 32) OVR\",\" 0.7333792628315535\"\n",
      "\"Decision Tree (gini, best, 64) OVO\",\" 0.7791939373062349\"\n",
      "\"Decision Tree (gini, best, 64) OVR\",\" 0.7333792628315535\"\n",
      "\"Decision Tree (gini, random, 2) OVO\",\" 0.6014467791939373\"\n",
      "\"Decision Tree (gini, random, 2) OVR\",\" 0.6637960730279022\"\n",
      "\"Decision Tree (gini, random, 4) OVO\",\" 0.6141922149500517\"\n",
      "\"Decision Tree (gini, random, 4) OVR\",\" 0.6958318980365139\"\n",
      "\"Decision Tree (gini, random, 8) OVO\",\" 0.7202893558387875\"\n",
      "\"Decision Tree (gini, random, 8) OVR\",\" 0.7437133999311057\"\n",
      "\"Decision Tree (gini, random, 16) OVO\",\" 0.765759559076817\"\n",
      "\"Decision Tree (gini, random, 16) OVR\",\" 0.7633482604202549\"\n",
      "\"Decision Tree (gini, random, 32) OVO\",\" 0.7809162934894937\"\n",
      "\"Decision Tree (gini, random, 32) OVR\",\" 0.7223561832586979\"\n",
      "\"Decision Tree (gini, random, 64) OVO\",\" 0.782983120909404\"\n",
      "\"Decision Tree (gini, random, 64) OVR\",\" 0.7168446434722701\"\n",
      "\"Decision Tree (entropy, best, 2) OVO\",\" 0.6737857388908026\"\n",
      "\"Decision Tree (entropy, best, 2) OVR\",\" 0.6658629004478126\"\n",
      "\"Decision Tree (entropy, best, 4) OVO\",\" 0.7061660351360661\"\n",
      "\"Decision Tree (entropy, best, 4) OVR\",\" 0.7020323802962453\"\n",
      "\"Decision Tree (entropy, best, 8) OVO\",\" 0.7543920082673097\"\n",
      "\"Decision Tree (entropy, best, 8) OVR\",\" 0.7581811918704788\"\n",
      "\"Decision Tree (entropy, best, 16) OVO\",\" 0.7805718222528419\"\n",
      "\"Decision Tree (entropy, best, 16) OVR\",\" 0.7798828797795384\"\n",
      "\"Decision Tree (entropy, best, 32) OVO\",\" 0.7785049948329315\"\n",
      "\"Decision Tree (entropy, best, 32) OVR\",\" 0.7423355149844988\"\n",
      "\"Decision Tree (entropy, best, 64) OVO\",\" 0.7819497071994489\"\n",
      "\"Decision Tree (entropy, best, 64) OVR\",\" 0.7502583534274888\"\n",
      "\"Decision Tree (entropy, random, 2) OVO\",\" 0.5749224939717533\"\n",
      "\"Decision Tree (entropy, random, 2) OVR\",\" 0.5638994143988977\"\n",
      "\"Decision Tree (entropy, random, 4) OVO\",\" 0.6972097829831209\"\n",
      "\"Decision Tree (entropy, random, 4) OVR\",\" 0.6779193937306235\"\n",
      "\"Decision Tree (entropy, random, 8) OVO\",\" 0.7306234929383396\"\n",
      "\"Decision Tree (entropy, random, 8) OVR\",\" 0.7588701343437823\"\n",
      "\"Decision Tree (entropy, random, 16) OVO\",\" 0.7747158112297623\"\n",
      "\"Decision Tree (entropy, random, 16) OVR\",\" 0.7781605235962797\"\n",
      "\"Decision Tree (entropy, random, 32) OVO\",\" 0.7771271098863245\"\n",
      "\"Decision Tree (entropy, random, 32) OVR\",\" 0.7264898380985187\"\n",
      "\"Decision Tree (entropy, random, 64) OVO\",\" 0.7833275921460559\"\n",
      "\"Decision Tree (entropy, random, 64) OVR\",\" 0.736823975198071\"\n",
      "\"SVM OVR (linear)\",\"0.7292456079917327\"\n",
      "\"SVM OVR (poly)\",\"0.7364795039614193\"\n",
      "\"SVM OVR (rbf)\",\"0.7506028246641405\"\n",
      "\"SVM OVR (sigmoid)\",\"0.6128143300034448\"\n",
      "\"Logistic Regression (l2) OVO\",\" 0.728901136755081\"\n",
      "\"Logistic Regression (l2) OVR\",\" 0.7240785394419565\"\n",
      "\"Logistic Regression (l1) OVO\",\" 0.7306234929383396\"\n",
      "\"Logistic Regression (l1) OVR\",\" 0.7244230106786084\"\n",
      "\"MLP (1, 16)\",\"0.7188146106955268\"\n",
      "\"MLP (1, 32)\",\"0.7305306684634013\"\n",
      "\"MLP (1, 64)\",\"0.7450034459815363\"\n",
      "\"MLP (1, 128)\",\"0.756719503872646\"\n",
      "\"MLP (1, 256)\",\"0.758442453562515\"\n",
      "\"MLP (2, 16)\",\"0.7401791866034331\"\n",
      "\"MLP (2, 32)\",\"0.7587870432540189\"\n",
      "\"MLP (2, 64)\",\"0.7763611304603881\"\n",
      "\"MLP (2, 128)\",\"0.8049620952711362\"\n",
      "\"MLP (2, 256)\",\"0.837008959174074\"\n",
      "\"MLP (4, 16)\",\"0.7319090282152966\"\n",
      "\"MLP (4, 32)\",\"0.7660234321979389\"\n",
      "\"MLP (4, 64)\",\"0.7922122674839485\"\n",
      "\"MLP (4, 128)\",\"0.8342522399167535\"\n",
      "\"MLP (4, 256)\",\"0.8345968296493357\"\n",
      "\"MLP (8, 16)\",\"0.7377670571608513\"\n",
      "\"MLP (8, 32)\",\"0.7649896621375475\"\n",
      "\"MLP (8, 64)\",\"0.7953135769257128\"\n",
      "\"MLP (8, 128)\",\"0.8228807718403828\"\n",
      "\"MLP (8, 256)\",\"0.8149552031437501\"\n",
      "\"Naive Bayes OVO\",\" 0.09441764300482426\"\n",
      "\"Naive Bayes OVR\",\" 0.12543073742246727\"\n",
      "\"Decision Tree (gini, best, 2) OVO\",\" 0.6709166092350103\"\n",
      "\"Decision Tree (gini, best, 2) OVR\",\" 0.6654031702274293\"\n",
      "\"Decision Tree (gini, best, 4) OVO\",\" 0.70434183321847\"\n",
      "\"Decision Tree (gini, best, 4) OVR\",\" 0.7012405237767058\"\n",
      "\"Decision Tree (gini, best, 8) OVO\",\" 0.7580978635423845\"\n",
      "\"Decision Tree (gini, best, 8) OVR\",\" 0.7546519641626465\"\n",
      "\"Decision Tree (gini, best, 16) OVO\",\" 0.7791178497587871\"\n",
      "\"Decision Tree (gini, best, 16) OVR\",\" 0.7698139214334941\"\n",
      "\"Decision Tree (gini, best, 32) OVO\",\" 0.7694693314955203\"\n",
      "\"Decision Tree (gini, best, 32) OVR\",\" 0.7250172294968987\"\n",
      "\"Decision Tree (gini, best, 64) OVO\",\" 0.7715368711233632\"\n",
      "\"Decision Tree (gini, best, 64) OVR\",\" 0.7229496898690558\"\n",
      "\"Decision Tree (gini, random, 2) OVO\",\" 0.5744314266023433\"\n",
      "\"Decision Tree (gini, random, 2) OVR\",\" 0.669882839421089\"\n",
      "\"Decision Tree (gini, random, 4) OVO\",\" 0.6691936595451413\"\n",
      "\"Decision Tree (gini, random, 4) OVR\",\" 0.6864231564438319\"\n",
      "\"Decision Tree (gini, random, 8) OVO\",\" 0.7091660923501034\"\n",
      "\"Decision Tree (gini, random, 8) OVR\",\" 0.7232942798070296\"\n",
      "\"Decision Tree (gini, random, 16) OVO\",\" 0.7770503101309442\"\n",
      "\"Decision Tree (gini, random, 16) OVR\",\" 0.7656788421778085\"\n",
      "\"Decision Tree (gini, random, 32) OVO\",\" 0.7694693314955203\"\n",
      "\"Decision Tree (gini, random, 32) OVR\",\" 0.7198483804272915\"\n",
      "\"Decision Tree (gini, random, 64) OVO\",\" 0.7705031013094418\"\n",
      "\"Decision Tree (gini, random, 64) OVR\",\" 0.715368711233632\"\n",
      "\"Decision Tree (entropy, best, 2) OVO\",\" 0.658855961405927\"\n",
      "\"Decision Tree (entropy, best, 2) OVR\",\" 0.6643694004135079\"\n",
      "\"Decision Tree (entropy, best, 4) OVO\",\" 0.6950379048931771\"\n",
      "\"Decision Tree (entropy, best, 4) OVR\",\" 0.6836664369400414\"\n",
      "\"Decision Tree (entropy, best, 8) OVO\",\" 0.7432804962095106\"\n",
      "\"Decision Tree (entropy, best, 8) OVR\",\" 0.7456926257753274\"\n",
      "\"Decision Tree (entropy, best, 16) OVO\",\" 0.7708476912474156\"\n",
      "\"Decision Tree (entropy, best, 16) OVR\",\" 0.7835975189524466\"\n",
      "\"Decision Tree (entropy, best, 32) OVO\",\" 0.7691247415575465\"\n",
      "\"Decision Tree (entropy, best, 32) OVR\",\" 0.7374224672639559\"\n",
      "\"Decision Tree (entropy, best, 64) OVO\",\" 0.7715368711233632\"\n",
      "\"Decision Tree (entropy, best, 64) OVR\",\" 0.7305306685044797\"\n",
      "\"Decision Tree (entropy, random, 2) OVO\",\" 0.5906271536871124\"\n",
      "\"Decision Tree (entropy, random, 2) OVR\",\" 0.638869745003446\"\n",
      "\"Decision Tree (entropy, random, 4) OVO\",\" 0.6795313576843556\"\n",
      "\"Decision Tree (entropy, random, 4) OVR\",\" 0.6767746381805652\"\n",
      "\"Decision Tree (entropy, random, 8) OVO\",\" 0.715368711233632\"\n",
      "\"Decision Tree (entropy, random, 8) OVR\",\" 0.7284631288766368\"\n",
      "\"Decision Tree (entropy, random, 16) OVO\",\" 0.7670572019297036\"\n",
      "\"Decision Tree (entropy, random, 16) OVR\",\" 0.78842177808408\"\n",
      "\"Decision Tree (entropy, random, 32) OVO\",\" 0.7839421088904204\"\n",
      "\"Decision Tree (entropy, random, 32) OVR\",\" 0.7415575465196417\"\n",
      "\"Decision Tree (entropy, random, 64) OVO\",\" 0.7753273604410751\"\n",
      "\"Decision Tree (entropy, random, 64) OVR\",\" 0.7122674017918676\"\n",
      "\"SVM OVR (linear)\",\"0.7184700206753962\"\n",
      "\"SVM OVR (poly)\",\"0.7291523087525844\"\n",
      "\"SVM OVR (rbf)\",\"0.7439696760854583\"\n",
      "\"SVM OVR (sigmoid)\",\"0.6188835286009648\"\n",
      "\"Logistic Regression (l2) OVO\",\" 0.7126119917298415\"\n",
      "\"Logistic Regression (l2) OVR\",\" 0.7112336319779462\"\n",
      "\"Logistic Regression (l1) OVO\",\" 0.71157822191592\"\n",
      "\"Logistic Regression (l1) OVR\",\" 0.7108890420399724\"\n"
     ]
    }
   ],
   "source": [
    "# Let's do a 10 cross-fold validation to explore the different models.\n",
    "ss = sklms.StratifiedKFold(n_splits = 10, shuffle = True)\n",
    "for train_idx, test_idx in ss.split(X, y):\n",
    "    X_tr = X[train_idx, :]\n",
    "    y_tr = y[train_idx]\n",
    "    y_oh_tr = y_oh[train_idx]\n",
    "    \n",
    "    X_te = X[test_idx, :]\n",
    "    y_te = y[test_idx]\n",
    "    y_oh_te = y_oh[test_idx]\n",
    "    \n",
    "    # Standard scalar, but only fit on the training data.\n",
    "    ss = sklpp.StandardScaler()\n",
    "    X_tr = ss.fit_transform(X_tr)\n",
    "    X_te = ss.transform(X_te)\n",
    "    \n",
    "    # What kind of models should we use? Some options we learned in class: tree, svm, bayesian, logistic,\n",
    "    # k-nearest neighbor, neural network.\n",
    "    # Should we tweak hyperparameters? Probably.\n",
    "    \n",
    "    # Since we have 7 classes, we need a multiclass classifier\n",
    "    # One-vs-one or one-vs-others? Let's try with both and see what's better.\n",
    "    \n",
    "    ### Neural Network ###\n",
    "    # Different configurations. Changing: layers and neurons per layer.\n",
    "    # num_layers list will be [2^0 = 1, 2^1 = 2, 2^2 = 4, 2^3 = 8]\n",
    "    for num_layers in exp_list(2, 0, 4):\n",
    "        # neurons_per_layer list will be [2^4 = 16, 2^5 = 32, 2^6 = 64, 2^7 = 128, 2^8 = 256]\n",
    "        for neurons_per_layer in exp_list(2, 4, 9):\n",
    "            # I used Keras to enable my GPU, otherwise sklearn's MLP takes forever.\n",
    "            classifier = km.Sequential()\n",
    "            classifier.add(kl.Dense(units = neurons_per_layer, activation = 'relu', input_dim = X_tr.shape[1]))\n",
    "            for i in range(num_layers - 1):\n",
    "                classifier.add(kl.Dense(units = neurons_per_layer, activation = 'relu'))\n",
    "            classifier.add(kl.Dense(units = y_oh_tr.shape[1], activation = 'softmax'))\n",
    "            classifier.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'], optimizer = 'Adam')\n",
    "            # Go until the loss doesn't change by any meaningful amount.\n",
    "            classifier.fit(X_tr, y_oh_tr,\n",
    "                           callbacks = [kc.EarlyStopping(monitor='loss', min_delta = 0.01, verbose=0)],\n",
    "                           epochs = 1000,\n",
    "                           verbose = 0)\n",
    "            print('\"MLP (' + str(num_layers) + ', ' + str(neurons_per_layer) + ')\",\"' + str(classifier.evaluate(X_te, y_oh_te, verbose = 0)[1]) + '\"')\n",
    "    \n",
    "    ### Naive Bayes ###\n",
    "    # No hyperparameters for Naive Bayes\n",
    "    classifier = sklnb.GaussianNB()\n",
    "    do_multi_label(classifier, 'Naive Bayes')    \n",
    "    \n",
    "    ### Decision Tree ###\n",
    "    # Different configurations. Changing: criterion, splitter, and max_depth.\n",
    "    for criterion in ['gini', 'entropy']:\n",
    "        for splitter in ['best', 'random']:\n",
    "            for max_depth in exp_list(2, 1, 7):\n",
    "                classifier = skltr.DecisionTreeClassifier(criterion = criterion, splitter = splitter, max_depth = max_depth)\n",
    "                do_multi_label(classifier, 'Decision Tree (' + criterion + ', ' + splitter + ', ' + str(max_depth) + ')')\n",
    "    \n",
    "    ### SVM ###\n",
    "    # Different configurations. Changing: penalty, kernel\n",
    "    # Scikit-learn's SVM implementation uses one-vs-rest classification under the hood, so we don't need to call\n",
    "    # do_multi_label here.\n",
    "    # The different kernel options transform the space to deal better with non-linear classes. Let's see if that helps.\n",
    "    for kernel in ['linear', 'poly', 'rbf', 'sigmoid']:\n",
    "        classifier = sklsvm.SVC(kernel = kernel)\n",
    "        classifier.fit(X_tr, y_tr)\n",
    "        print('\"SVM OVR (' + kernel + ')\",\"' + str(classifier.score(X_te, y_te)) + '\"')\n",
    "    \n",
    "    ### Logistic Regression ###\n",
    "    # Different configurations. Changing: penalty\n",
    "    for penalty in ['l2', 'l1']:\n",
    "        classifier = skllm.LogisticRegression(penalty = penalty)\n",
    "        do_multi_label(classifier, 'Logistic Regression (' + penalty + ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "\n",
    "# The Naive Bayes classifier was the worst. This is probably because the Naive Bayes works much better for categorical\n",
    "# data, yet we had a lot of continuous data, like elevation. This is probably a bad application for the Naive Bayes,\n",
    "# but it's interesting to see the accuracy results for it, anyway.\n",
    "\n",
    "# What surprised me is the results for the SVM kernels. Even after transforming the space, the kernels ranged 72-76\n",
    "# accuracy. I thought that it would do much better after the nonlinear transformation, but it only improved by a few\n",
    "# percentage points. (Maybe a little better than logistic regression.) The kernels did help a little bit, bringing\n",
    "# accuracy for rbf to 72-76 and poly to 72-75, whereas linear kernel was 70-73, but I expected the improvement to be\n",
    "# much more pronounced. Maybe the feature space was already mostly linear before the transformation, so the nonlinear\n",
    "# transformation didn't help that much.\n",
    "\n",
    "# In addition to being surprised by how little the nonlinear kernels helped the SVM, I'm surprised by how well the\n",
    "# decision tree performed. Thinking about it more in depth, decision trees have separation boundaries orthogonal to the\n",
    "# space. If the decision tree depth is unbounded, they can split the space any number of times. This actually turns out\n",
    "# to be pretty similar to a neural network, except neural network decision boundaries don't necessarily have to be\n",
    "# orthogonal to the space. Assuming a ReLU, each neuron in the neural network creates another \"kink\" in the decision\n",
    "# boundary. Similarly, each layer in a decision tree creates a number of kinks equal to the number of decisions made\n",
    "# at that level. Thus, we can actually think of an unbounded decision tree as similar to a neural network, except that\n",
    "# its decisions are constrained to orthogonal hyperplanes.\n",
    "\n",
    "# Logistic regression performed about as well as the linear SVM. I think this makes sense, because they are pretty\n",
    "# similar. The SVM follows linear class boundaries whereas the logistic regression follows linear midway probability line.\n",
    "# The SVM creates stark linear boundaries between the classes, but the logistic regression classifier doesn't create\n",
    "# boundaries. It creates different degrees of certainty eminating from that line.\n",
    "\n",
    "# Lastly, the neural network performed the best, as expected. We had to do some tweaks to find out which shape, roughly,\n",
    "# was the best for it, but the neural network with 4 hidden layers and 256 nodes per layer turned out to be the best,\n",
    "# achieving an accuracy of 83-85. Any less than that, and there were not enough neurons to learn all the nuances of this\n",
    "# dataset, but any more than that, and the network started overfitting on the training data.\n",
    "\n",
    "# Overall, it looks like the neural network approach is probably best for this data, but the decision tree approach also\n",
    "# looks fruitful, and took much less runtime than the neural network. Decision trees with entropy performed slightly\n",
    "# better than decision trees with the gini coefficient, and it looks like constraining the depth of the decision tree\n",
    "# to 32 or 64 is best. One decision tree even managed to break 80% for one of the crossfold validations (entropy, best\n",
    "# split, 32 max height)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
